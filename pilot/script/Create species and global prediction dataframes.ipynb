{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import plotting_extent\n",
    "from natsort import natsorted\n",
    "import gdal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import rasterio\n",
    "import pycrs\n",
    "\n",
    "file_dir=r'C:/Users/Mark.Rademaker/PycharmProjects/InternshipNaturalis/trait-geo-diverse-dl/concept proof'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All species dataframes now in dictionary\n"
     ]
    }
   ],
   "source": [
    "#access file with list of taxa names\n",
    "taxa=pd.read_csv(file_dir+\"/data/spec_filtered/taxa.txt\",header=None)\n",
    "taxa.columns=[\"taxon\"]\n",
    "\n",
    "species_occ_dict={}\n",
    "\n",
    "for i in taxa[\"taxon\"]:\n",
    "    taxon_data = pd.read_csv(file_dir+\"/data/spec_filtered/%s.csv\"%i)\n",
    "    #add species dataframe to dict\n",
    "    species_occ_dict[\"%s\"%i] = taxon_data  \n",
    "    #check whether all species have been included and inspect dictionary\n",
    "if len(species_occ_dict.keys())==len(taxa[\"taxon\"]):\n",
    "    print(\"All species dataframes now in dictionary\")\n",
    "else:\n",
    "    print(\"Error: not all species dataframe included\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "- First read in occurrence data\n",
    "- Create a copy that we can use in the original state later\n",
    "- Create a buffer around each occurrence point, merge it into a single polygon\n",
    "- Clip the environmental raster based on this extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in species_occ_dict:    \n",
    "    #load occurrence data and set initial projection\n",
    "    data=species_occ_dict[key]\n",
    "    print(data.columns)\n",
    "    spec = key\n",
    "\n",
    "\n",
    "    data['coordinates'] = list(zip(data[\"decimal_longitude\"], data[\"decimal_latitude\"]))\n",
    "    data['coordinates'] = data[\"coordinates\"].apply(Point)\n",
    "    data[\"present/pseudo_absent\"]=1\n",
    "    geo_data=geopandas.GeoDataFrame(data, geometry='coordinates',crs={'init' :'epsg:4326'})\n",
    "\n",
    "    #change projection to azimuthal equidistant to calculate 1000km buffer around point\n",
    "    geo_data = geo_data.to_crs({'init': 'esri:54032'}) \n",
    "    buffer=geo_data.buffer(1000*1000)\n",
    "    buffer=buffer.to_crs(epsg=4326)\n",
    "\n",
    "    #create single large polygon from individual buffers\n",
    "    union_buffer=buffer.unary_union\n",
    "\n",
    "    #first clip the raster based on this extend \n",
    "    raster=rasterio.open(file_dir+'/data/GIS/env_stacked/ENVIREM_BIOCLIM_stacked.tif')\n",
    "    #specify output tif:\n",
    "    out_tif = file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec\n",
    "\n",
    "    #clip the raster:\n",
    "    out_img, out_transform = mask(dataset=raster, shapes=[union_buffer],crop=True)\n",
    "   \n",
    "    # Copy the metadata\n",
    "    out_meta = raster.meta.copy()\n",
    "\n",
    "    # Parse EPSG code\n",
    "    epsg_code = int(raster.crs.data['init'][5:])\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_img.shape[1],\n",
    "                     \"width\": out_img.shape[2],\n",
    "                     \"transform\": out_transform,\n",
    "                     \"crs\": pycrs.parse.from_epsg_code(epsg_code).to_proj4()})\n",
    "\n",
    "    with rasterio.open(out_tif, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect whether clip was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the first band of the clipped raster for all species\n",
    "for key in species_occ_dict:\n",
    "    ##### Extract occurrence point to plot on the raster (see if correct area was clipped)\n",
    "    data=species_occ_dict[key]\n",
    "    print(len(data.index))\n",
    "    spec = key\n",
    "    data['coordinates'] = list(zip(data[\"decimal_longitude\"], data[\"decimal_latitude\"]))\n",
    "    data['coordinates'] = data[\"coordinates\"].apply(Point)\n",
    "    geo_data=geopandas.GeoDataFrame(data, geometry='coordinates',crs={'init' :'epsg:4326'})\n",
    "    ####open the clipped raster\n",
    "    clipped = rasterio.open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    array = clipped.read(1)\n",
    "    array_data = clipped.read(1,masked=True)\n",
    "    array_meta = clipped.profile\n",
    "   \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(array_data,cmap=\"gist_earth\",interpolation=\"none\",vmin=0,\n",
    "    # Here you must set the spatial extent or else the data will not line up with your geopandas layer\n",
    "    extent=plotting_extent(clipped),)\n",
    "    spec_plots_points=geo_data[\"coordinates\"]\n",
    "    spec_plots_points.plot(ax=ax,\n",
    "                       marker='o',\n",
    "                       markersize=20,\n",
    "                       color='red')\n",
    "    ax.set_title(\"%s \\n Raster clip and occurrence points\"%spec,\n",
    "             fontsize=20)\n",
    "    plt.show()\n",
    "#Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "- now that we have the clipped raster we can use it to try and make a random selection of pseudo absence points\n",
    "- we first open the raster\n",
    "- then we separate those cells that actually contain pixel values (excluding the sea)\n",
    "- we calculate the longitude and latitude of the centre point of these cells <br>\n",
    "  (the environmental variable values do not vary within each cell so it doesn't matter if each points is in the centre)\n",
    "- we make a random selection of 1000 positions (in line with Hendrix & Vos)\n",
    "- we add the longitude and latitude values of these to to the dataset and export it  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in species_occ_dict:    \n",
    "    #lon_lat presence points\n",
    "    presence_data = species_occ_dict[key]\n",
    "    presence_data[\"present/pseudo_absent\"]=1\n",
    "    spec = key\n",
    "    long=presence_data[\"decimal_longitude\"]\n",
    "    lati=presence_data[\"decimal_latitude\"]\n",
    "    long=pd.Series.tolist(long)\n",
    "    lati=pd.Series.tolist(lati)\n",
    "   \n",
    "    \n",
    "    \n",
    "    #read raster\n",
    "    src=rasterio.open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    array=src.read_masks(1)\n",
    "    \n",
    "    #set raster cell mask values of presence locations to 1\n",
    "    for i in range(0,len(presence_data)):\n",
    "        row,col=src.index(long[i],lati[i])\n",
    "        array[row,col]=1\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(array,cmap=\"gray\")\n",
    "    ax.set_title(\"%s\"%spec,\n",
    "             fontsize=20)\n",
    "    plt.show()\n",
    "    print(len(presence_data), \"number of presences\")\n",
    "    \n",
    "    (y_index, x_index) = np.nonzero(array > 1)\n",
    "\n",
    "    #sample random locations from raster excluding sea and presence cells\n",
    "    r = gdal.Open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    (upper_left_x, x_size, x_rotation, upper_left_y, y_rotation, y_size) = r.GetGeoTransform()\n",
    "    x_coords = x_index * x_size + upper_left_x + (x_size / 2) #add half the cell size\n",
    "    y_coords = y_index * y_size + upper_left_y + (y_size / 2) #to centre the point\n",
    "\n",
    "\n",
    "    lon_lat_array=np.stack((x_coords,y_coords)).T\n",
    "\n",
    "    random_sample_size=1000\n",
    "    random_sample_lon_lats=lon_lat_array[np.random.choice(lon_lat_array.shape[0], 1000, replace=False), :] ##\n",
    "    print(len(random_sample_lon_lats), \"number of pseudo absences\")\n",
    "\n",
    "    #Add random points to dataset\n",
    "    lon=[]\n",
    "    lat=[]\n",
    "    psa=[0]*random_sample_size\n",
    "    taxon=[\"%s\"%spec]*random_sample_size\n",
    "    gbif=[\"no_id\"]*random_sample_size\n",
    "\n",
    "    for item in random_sample_lon_lats:\n",
    "        longitude=item[0]\n",
    "        latitude=item[1]\n",
    "        lon.append(longitude)\n",
    "        lat.append(latitude)\n",
    "\n",
    "    ###Dataset including 10.000 pseudo-absence points for capriolus capriolus\n",
    "    new_data=pd.DataFrame({\"gbif_id\": gbif,\"taxon_name\":taxon,\"decimal_longitude\": lon, \"decimal_latitude\":lat, \"present/pseudo_absent\": psa})\n",
    "    data=pd.concat([presence_data,new_data],ignore_index=True)\n",
    "    data=data[['taxon_name','gbif_id','decimal_longitude','decimal_latitude','present/pseudo_absent']]\n",
    "    data[\"row_n\"]=np.arange(len(data))\n",
    "     \n",
    "    long=data[\"decimal_longitude\"]\n",
    "    lati=data[\"decimal_latitude\"]\n",
    "    long=pd.Series.tolist(long)\n",
    "    lati=pd.Series.tolist(lati)\n",
    "    \n",
    "    print(len(data),\"lenght data with pseudo absences pre-filtering\")\n",
    "    \n",
    "    #read raster\n",
    "    src=rasterio.open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    array=src.read_masks(1)\n",
    "    \n",
    "    ##remove potential presence locations in the sea##\n",
    "    for i in range(1,42):\n",
    "        array=src.read_masks(i)\n",
    "        for i in range(0,len(data)):\n",
    "            row,col=src.index(long[i],lati[i])\n",
    "            if array[row,col] ==0:\n",
    "                data=data[data.row_n != i]     \n",
    "    print(len(data), \"length data with pseudo absences post-filtering\")\n",
    "    \n",
    "    \n",
    "    data=data.reset_index(drop=True)\n",
    "    data.to_csv(file_dir + \"/data/spec_occ/%s_occ_dataframe.csv\"%spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(file_dir+'/data/spec_occ_env/Vicagna_vicugna_env_dataframe.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3 \n",
    "- finally we can extract the environmental variable values underneath the occurrence and pseudo-absence points\n",
    "- we need to scale these environmental values for later training by taking their mean and std_dev\n",
    "- below is a code snippet, but because it requires a long time to run in jupyter the process is best split (see extract_env_variables1-4.py files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster=rasterio.open(file_dir+'/data/GIS/env_stacked/ENVIREM_BIOCLIM_stacked.tif')\n",
    "array = raster.read()\n",
    "\n",
    "with open(file_dir+'/data/GIS/env_bio_mean_std.txt','w+') as file:\n",
    "    file.write(\"band\"+\"\\t\"+\"mean\"+\"\\t\"+\"std_dev\"+\"\\n\")\n",
    "    file.close()\n",
    "\n",
    "\n",
    "min_max=0\n",
    "\n",
    "for band in array:\n",
    "    minb=np.min(band)\n",
    "    if minb < min_max:\n",
    "        min_max=minb\n",
    "\n",
    "\n",
    "for i in range(1,42):\n",
    "    print(i)\n",
    "    profile.update(count=1)\n",
    "    band=raster.read(i)\n",
    "    band[band == -9999] = min_max\n",
    "    band_masked = np.ma.masked_array(band, mask=(band == min_max))\n",
    "    \n",
    "    mean=band_masked.mean()\n",
    "    std_dev=np.std(band_masked)\n",
    "    with open(file_dir+'/data/GIS/env_bio_mean_std.txt','a') as file:\n",
    "        file.write(str(i)+\"\\t\"+str(mean)+\"\\t\"+str(std_dev)+\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Subset the dataframe into four parts\n",
    "#access file with list of taxa names\n",
    "taxa=pd.read_csv(file_dir+\"/data/spec_filtered/taxa.txt\",header=None)\n",
    "taxa.columns=[\"taxon\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing species  Aepyceros_melampus\n",
      "processing species  Alcelaphus_buselaphus\n",
      "processing species  Alcelaphus_caama\n",
      "processing species  Alces_alces\n",
      "processing species  Alces_americanus\n",
      "processing species  Ammotragus_lervia\n",
      "processing species  Antidorcas_marsupialis\n",
      "processing species  Antilocapra_americana\n",
      "processing species  Antilope_cervicapra\n",
      "processing species  Axis_axis\n",
      "processing species  Axis_porcinus\n",
      "processing species  Bison_bison\n",
      "processing species  Bison_bonasus\n",
      "processing species  Blastocerus_dichotomus\n",
      "processing species  Bos_frontalis_gaurus\n",
      "processing species  Bos_grunniens_mutus\n",
      "processing species  Bos_javanicus\n",
      "processing species  Bos_taurus_primigenius\n",
      "processing species  Boselaphus_tragocamelus\n",
      "processing species  Bubalus_bubalis_arnee\n",
      "processing species  Budorcas_taxicolor\n",
      "processing species  Camelus_bactrianus\n",
      "processing species  Camelus_dromedarius\n",
      "processing species  Capra_hircus_aegagrus\n",
      "processing species  Capra_ibex\n",
      "processing species  Capra_nubiana\n",
      "processing species  Capra_pyrenaica\n",
      "processing species  Capra_sibirica\n",
      "processing species  Capreolus_capreolus\n",
      "processing species  Capreolus_pygargus\n",
      "processing species  Capricornis_crispus\n",
      "processing species  Capricornis_swinhoei\n",
      "processing species  Catagonus_wagneri\n",
      "processing species  Cephalophus_dorsalis\n",
      "processing species  Cephalophus_jentinki\n",
      "processing species  Cephalophus_natalensis\n",
      "processing species  Cephalophus_niger\n",
      "processing species  Cephalophus_nigrifrons\n",
      "processing species  Cephalophus_rufilatus\n",
      "processing species  Cephalophus_silvicultor\n",
      "processing species  Cephalophus_zebra\n",
      "processing species  Ceratotherium_simum\n",
      "processing species  Cervus_elaphus\n",
      "processing species  Cervus_nippon\n",
      "processing species  Connochaetes_gnou\n",
      "processing species  Connochaetes_taurinus\n",
      "processing species  Dama_dama\n",
      "processing species  Damaliscus_korrigum\n",
      "processing species  Damaliscus_lunatus\n",
      "processing species  Damaliscus_pygargus\n",
      "processing species  Diceros_bicornis\n",
      "processing species  Equus_burchellii\n",
      "processing species  Equus_grevyi\n",
      "processing species  Equus_hemionus\n",
      "processing species  Equus_kiang\n",
      "processing species  Equus_przewalskii\n",
      "processing species  Equus_zebra\n",
      "processing species  Eudorcas_rufifrons\n",
      "processing species  Eudorcas_thomsonii\n",
      "processing species  Gazella_bennettii\n",
      "processing species  Gazella_dorcas\n",
      "processing species  Gazella_gazella\n",
      "processing species  Gazella_subgutturosa\n",
      "processing species  Giraffa_camelopardalis\n",
      "processing species  Hemitragus_jemlahicus\n",
      "processing species  Hippocamelus_antisensis\n",
      "processing species  Hippocamelus_bisulcus\n",
      "processing species  Hippopotamus_amphibius\n",
      "processing species  Hippotragus_equinus\n",
      "processing species  Hippotragus_niger\n",
      "processing species  Hyemoschus_aquaticus\n",
      "processing species  Hylochoerus_meinertzhageni\n",
      "processing species  Kobus_ellipsiprymnus\n",
      "processing species  Kobus_kob\n",
      "processing species  Kobus_leche\n",
      "processing species  Kobus_megaceros\n",
      "processing species  Kobus_vardonii\n",
      "processing species  Lama_glama_guanicoe\n",
      "processing species  Litocranius_walleri\n",
      "processing species  Madoqua_guentheri\n",
      "processing species  Madoqua_kirkii\n",
      "processing species  Madoqua_saltiana\n",
      "processing species  Mazama_americana\n",
      "processing species  Mazama_gouazoubira\n",
      "processing species  Mazama_nana\n",
      "processing species  Mazama_pandora\n",
      "processing species  Mazama_rufina\n",
      "processing species  Mazama_temama\n",
      "processing species  Muntiacus_muntjak\n",
      "processing species  Muntiacus_reevesi\n",
      "processing species  Nanger_granti\n",
      "processing species  Nanger_soemmerringii\n",
      "processing species  Neotragus_batesi\n",
      "processing species  Neotragus_pygmaeus\n",
      "processing species  Odocoileus_hemionus\n",
      "processing species  Odocoileus_virginianus\n",
      "processing species  Oreamnos_americanus\n",
      "processing species  Oreotragus_oreotragus\n",
      "processing species  Oryx_beisa\n",
      "processing species  Oryx_gazella\n",
      "processing species  Oryx_leucoryx\n",
      "processing species  Ourebia_ourebi\n",
      "processing species  Ovibos_moschatus\n",
      "processing species  Ovis_ammon\n",
      "processing species  Ovis_aries_orientalis\n",
      "processing species  Ovis_canadensis\n",
      "processing species  Ovis_dalli\n",
      "processing species  Ozotoceros_bezoarticus\n",
      "processing species  Pecari_tajacu\n",
      "processing species  Pelea_capreolus\n",
      "processing species  Phacochoerus_aethiopicus\n",
      "processing species  Phacochoerus_africanus\n",
      "processing species  Philantomba_maxwellii\n",
      "processing species  Philantomba_monticola\n",
      "processing species  Potamochoerus_larvatus\n",
      "processing species  Potamochoerus_porcus\n",
      "processing species  Procapra_picticaudata\n",
      "processing species  Pseudois_nayaur\n",
      "processing species  Pudu_puda\n",
      "processing species  Rangifer_tarandus\n",
      "processing species  Raphicerus_campestris\n",
      "processing species  Raphicerus_melanotis\n",
      "processing species  Raphicerus_sharpei\n",
      "processing species  Redunca_arundinum\n",
      "processing species  Redunca_fulvorufula\n",
      "processing species  Redunca_redunca\n",
      "processing species  Rhinoceros_unicornis\n",
      "processing species  Rucervus_duvaucelii\n",
      "processing species  Rupicapra_pyrenaica\n",
      "processing species  Rupicapra_rupicapra\n",
      "processing species  Rusa_timorensis\n",
      "processing species  Rusa_unicolor\n",
      "processing species  Sus_barbatus\n",
      "processing species  Sus_cebifrons\n",
      "processing species  Sus_philippensis\n",
      "processing species  Sus_scrofa\n",
      "processing species  Sylvicapra_grimmia\n",
      "processing species  Syncerus_caffer\n",
      "processing species  Tapirus_bairdii\n",
      "processing species  Tapirus_pinchaque\n",
      "processing species  Tapirus_terrestris\n",
      "processing species  Taurotragus_oryx\n",
      "processing species  Tayassu_pecari\n",
      "processing species  Tragelaphus_angasii\n",
      "processing species  Tragelaphus_buxtoni\n",
      "processing species  Tragelaphus_eurycerus\n",
      "processing species  Tragelaphus_imberbis\n",
      "processing species  Tragelaphus_scriptus\n",
      "processing species  Tragelaphus_spekii\n",
      "processing species  Tragelaphus_strepsiceros\n",
      "processing species  Tragulus_javanicus\n",
      "processing species  Tragulus_kanchil\n",
      "processing species  Tragulus_napu\n",
      "processing species  Vicagna_vicugna\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "\n",
    "for i in taxa[\"taxon\"]:\n",
    "    data = pd.read_csv(file_dir+\"/data/spec_occ/%s_occ_dataframe.csv\"%i)\n",
    "    \n",
    "    spec = data[\"taxon_name\"][0]\n",
    "    spec = spec.replace(\" \",\"_\")\n",
    "    \n",
    "    print(\"processing species \", spec)\n",
    "    \n",
    "\n",
    "    #get all col and row values for species locations \n",
    "    len_pd=np.arange(len(data))\n",
    "    long=data[\"decimal_longitude\"]\n",
    "    lati=data[\"decimal_latitude\"]\n",
    "    ppa=data[\"present/pseudo_absent\"]\n",
    "\n",
    "    lon=long.values\n",
    "    lat=lati.values\n",
    "\n",
    "    row=[]\n",
    "    col=[]\n",
    "\n",
    "    src=rasterio.open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "\n",
    "    for i in len_pd:\n",
    "        row_n, col_n = src.index(lon[i], lat[i])# spatial --> image coordinates\n",
    "        row.append(row_n)\n",
    "        col.append(col_n)\n",
    "\n",
    "    ##opening raster as 3d numpy array\n",
    "    inRas=gdal.Open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    myarray=inRas.ReadAsArray()\n",
    "    #print(myarray.shape)\n",
    "    #print(type(myarray))\n",
    "\n",
    "    #collect file with mean and std_dev for each band\n",
    "    mean_std=pd.read_csv(file_dir+'/data/GIS/env_bio_mean_std.txt',sep=\"\\t\")\n",
    "    mean_std=mean_std.to_numpy()\n",
    "\n",
    "\n",
    "    ########################################################\n",
    "    #extract the values for all bands and prepare input data\n",
    "    ########################################################\n",
    "    X=[]\n",
    "    species =[\"%s\"%spec]*int(len(row))\n",
    "\n",
    "    for j in range(0,41):\n",
    "        band=myarray[j]\n",
    "        x=[]\n",
    "\n",
    "        for i in range(0,len(row)):\n",
    "            value= band[row[i],col[i]]\n",
    "            if value <-1000:\n",
    "                value=np.nan\n",
    "                x.append(value)\n",
    "            else:\n",
    "                value = ((value - mean_std.item((j,1))) / mean_std.item((j,2)))#scale values\n",
    "                x.append(value)\n",
    "        X.append(x)\n",
    "\n",
    "\n",
    "    #set as numpy 2d array\n",
    "    X =np.array([np.array(xi) for xi in X])\n",
    "\n",
    "    #transform into dataframe and include row and column values\n",
    "    df=pd.DataFrame(X)\n",
    "    df=df.T\n",
    "\n",
    "    df[\"present/pseudo_absent\"]=ppa\n",
    "    df[\"decimal_latitude\"]=lati\n",
    "    df[\"decimal_longitude\"]=long\n",
    "    df[\"taxon_name\"]=species\n",
    "    df[\"present/pseudo_absent\"]=ppa\n",
    "    df[\"row_n\"]=row\n",
    "    \n",
    "    df=df.dropna(axis=0, how='any')\n",
    "    input_data=df\n",
    "    ##save input dataframe\n",
    "    input_data.to_csv(file_dir +\"/data/spec_occ_env/%s_env_dataframe.csv\"%spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "experimental code, check whether keeping this is necessary later, first create dataframe with all locations in world, <br>\n",
    "then extract environmental values at all these cells and store into array for later DNN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ###Dataset of world map including all locations with data-values (to later predict presence-pseudoabsence on)\n",
    "    src=rasterio.open(file_dir+'/data/GIS/env_stacked/ENVIREM_BIOCLIM_stacked.tif')\n",
    "    array=src.read_masks(1)\n",
    "    \n",
    "    r = gdal.Open(file_dir+'/data/GIS/env_stacked/ENVIREM_BIOCLIM_stacked.tif')\n",
    "    (y_index, x_index) = np.nonzero(array > 0)\n",
    "    (upper_left_x, x_size, x_rotation, upper_left_y, y_rotation, y_size) = r.GetGeoTransform()\n",
    "    x_coords = x_index * x_size + upper_left_x + (x_size / 2) #add half the cell size\n",
    "    y_coords = y_index * y_size + upper_left_y + (y_size / 2) #to centre the point\n",
    "\n",
    "    lon_lat_array=np.stack((x_coords,y_coords)).T\n",
    "\n",
    "    lon=[]\n",
    "    lat=[]\n",
    "\n",
    "    for item in lon_lat_array:\n",
    "        longitude=item[0]\n",
    "        latitude=item[1]\n",
    "        lon.append(longitude)\n",
    "        lat.append(latitude)\n",
    "\n",
    "    taxon=[\"%s\"%spec]*len(lon)\n",
    "\n",
    "    data_to_pred=pd.DataFrame({\"decimal_longitude\":lon,\"decimal_latitude\":lat})\n",
    "    print(len(data_to_pred), \"number of points to predict\")\n",
    "    data_to_pred.to_csv(file_dir + \"/data/GIS/world_locations_to_predict.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 1800, 4320)\n",
      "<class 'numpy.ndarray'>\n",
      "[      0       1       2 ... 2179454 2179455 2179456]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "\n",
    "##opening raster as 3d numpy array\n",
    "inRas=gdal.Open(file_dir+'/data/GIS/env_stacked/ENVIREM_BIOCLIM_stacked.tif')\n",
    "myarray=inRas.ReadAsArray()\n",
    "print(myarray.shape)\n",
    "print(type(myarray))\n",
    "\n",
    "#get all col and row values for all cells on land \n",
    "df=pd.read_csv(file_dir+'/data/GIS/world_locations_to_predict.csv')\n",
    "len_pd=np.arange(len(df))\n",
    "print(len_pd)\n",
    "lon=df[\"decimal_longitude\"]\n",
    "lat=df[\"decimal_latitude\"]\n",
    "lon=lon.values\n",
    "lat=lat.values\n",
    "\n",
    "row=[]\n",
    "col=[]\n",
    "\n",
    "src=rasterio.open(file_dir+'/data/GIS/env_stacked/ENVIREM_BIOCLIM_stacked.tif')\n",
    "\n",
    "for i in len_pd:\n",
    "    row_n, col_n = src.index(lon[i], lat[i])# spatial --> image coordinates\n",
    "    row.append(row_n)\n",
    "    col.append(col_n)\n",
    "\n",
    "#collect file with mean and std_dev for each band\n",
    "mean_std=pd.read_csv(file_dir+'/data/GIS/env_bio_mean_std.txt',sep=\"\\t\")\n",
    "mean_std=mean_std.to_numpy()\n",
    "\n",
    "\n",
    "########################################################\n",
    "#extract the values for all bands and prepare input data\n",
    "########################################################\n",
    "X=[]\n",
    "\n",
    "for j in range(0,41):\n",
    "    print(j)\n",
    "    band=myarray[j]\n",
    "    x=[]\n",
    "\n",
    "    for i in range(0,len(row)):\n",
    "        value= band[row[i],col[i]]\n",
    "        if value <-1000:\n",
    "            value=np.nan\n",
    "            x.append(value)\n",
    "        else:\n",
    "            value = ((value - mean_std.item((j,1))) / mean_std.item((j,2)))#scale values\n",
    "            x.append(value)\n",
    "    X.append(x)\n",
    "\n",
    "#include row and column values\n",
    "X.append(row)\n",
    "X.append(col)\n",
    "#set as numpy 2d array\n",
    "X =np.array([np.array(xi) for xi in X])\n",
    "\n",
    "df=pd.DataFrame(X)\n",
    "\n",
    "df=df.T\n",
    "df=df.dropna(axis=0, how='any')\n",
    "input_X=df.loc[:,0:40]\n",
    "\n",
    "\n",
    "row=df[41]\n",
    "col=df[42]\n",
    "\n",
    "row_col=pd.DataFrame({\"row\":row,\"col\":col})\n",
    "\n",
    "#convert dataframe back to numpy array\n",
    "input_X=input_X.values\n",
    "#convert rows and col indices back to array\n",
    "row=row.values\n",
    "col=col.values\n",
    "\n",
    "#save\n",
    "prediction_array=np.save(file_dir+'/data/GIS/world_prediction_array.npy',input_X)\n",
    "prediction_pandas=row_col.to_csv(file_dir+'/data/GIS/world_prediction_row_col.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
