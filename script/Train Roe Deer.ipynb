{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from deepviz.guided_backprop import GuidedBackprop\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics.ranking import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "\n",
    "    import keras.backend as K\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation\n",
    "    from keras.optimizers import RMSprop\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.optimizers import Adagrad\n",
    "    from keras.optimizers import SGD\n",
    "    from keras.callbacks import LambdaCallback, ReduceLROnPlateau, ModelCheckpoint\n",
    "    from keras.layers.core import Lambda\n",
    "    from keras.losses import categorical_crossentropy\n",
    "    import tensorflow as tf\n",
    "    from keras import regularizers\n",
    "except:\n",
    "    print(\"Keras not found\")\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def my_basename(path):\n",
    "    return os.path.splitext(os.path.split(path)[1])[0]\n",
    "\n",
    "file_dir=r'C:/Users/M-RAM/PycharmProjects/InternshipNaturalis/github_trait_geo_diverse_dl/trait-geo-diverse-dl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    table = pd.read_csv(file_dir +\"/data/capriolus_trial/Capriolus_capriolus_env_dataframe.csv\")\n",
    "\n",
    "    table =table.loc[:1500]\n",
    "    # at 40 degrees latitude\n",
    "    bin_size_km = 5\n",
    "    one_degree_latitude_km = 111.03  # http://www.longitudestore.com/how-big-is-one-gps-degree.html\n",
    "    one_degree_longitude_km = 85.39\n",
    "    step_latitude = 1. / one_degree_latitude_km * bin_size_km\n",
    "    step_longitude = 1. / one_degree_longitude_km * bin_size_km\n",
    "    # print(\"step_latitude, step_longitude\", step_latitude, step_longitude)\n",
    "\n",
    "    # remove spaces from column names\n",
    "    for column in table.columns:\n",
    "        table[column.strip()] = table[column]\n",
    "        if column.strip() != column:\n",
    "            del table[column]\n",
    "    # print(table.columns)\n",
    "    # print(table.decimal_latitude.min(), table.decimal_latitude.max())\n",
    "\n",
    "    latitude_min = table.decimal_latitude.min()\n",
    "    longitude_min = table.decimal_longitude.min()\n",
    "    table.decimal_latitude = table.decimal_latitude.apply(lambda x: (x - latitude_min) // step_latitude)\n",
    "    table.decimal_longitude = table.decimal_longitude.apply(lambda x: (x - longitude_min) // step_longitude)\n",
    "    table.decimal_latitude = table.decimal_latitude.astype(int)\n",
    "    table.decimal_longitude = table.decimal_longitude.astype(int)\n",
    "\n",
    "    # make feature vector\n",
    "    band_columns = [column for column in table.columns[8:]]\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, row in table.iterrows():\n",
    "        x = row[band_columns].values\n",
    "        if (np.any(x <= -9999.0)):  # in sea?\n",
    "            continue\n",
    "        # print(row[\"present/pseudo_absent\"], np.where(x <= -9999.0)[0])\n",
    "        x = x.tolist()\n",
    "        x.append(row[\"present/pseudo_absent\"])\n",
    "        X.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data=X, columns=band_columns + [\"presence\"])\n",
    "    df.to_csv(\"filtered.csv\", index=None)\n",
    "\n",
    "    print(len(df[df[\"presence\" ]==1]))\n",
    "    print(len(df[df[\"presence\" ]==0]))\n",
    "\n",
    "    # Scale feature values\n",
    "    for column in df.columns[:-1]:\n",
    "        # if \"band\" in column:\n",
    "        std_dev = np.std(df[column])\n",
    "        mean_ = np.mean(df[column])\n",
    "        df[column] = df[column].apply(lambda x: (x - mean_) / std_dev)\n",
    "    df.to_csv(\"normalized.csv\", index=None)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    band_columns = [column for column in df.columns[:-1]]\n",
    "    # print(band_columns)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(row[band_columns].values.tolist())\n",
    "        y.append([1 - row[\"presence\"], row[\"presence\"]])\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    y = np.vstack(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "    batch_size = 100\n",
    "    num_classes = 2\n",
    "    epochs = 500\n",
    "\n",
    "    num_inputs = X.shape[1]  # number of features\n",
    "\n",
    "    model = Sequential()\n",
    "    layer_1 = Dense(50, activation='relu', input_shape=(num_inputs,), kernel_regularizer=regularizers.l1(0.01))\n",
    "\n",
    "    layer_2 = Dense(25, activation='relu', input_shape=(num_inputs,), kernel_regularizer=regularizers.l1(0.01))\n",
    "\n",
    "    model.add(layer_1)\n",
    "    model.add(layer_2)\n",
    "\n",
    "    # model.add(Dropout(0.5))\n",
    "\n",
    "    # model.add(Lambda(lambda x: K.dropout(x, level=0.5)))\n",
    "    # model.add(Dense(512, activation='relu',\n",
    "    #             # kernel_regularizer=regularizers.l2(0.01),\n",
    "    #             # activity_regularizer=regularizers.l1(0.01)\n",
    "    #                 ))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(Lambda(lambda x: K.dropout(x, level=0.5)))\n",
    "    out_layer = Dense(num_classes, activation=None)\n",
    "    model.add(out_layer)\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                 optimizer =SGD(lr=0.001, momentum =0.9, nesterov=True),\n",
    "                # optimizer=Adagrad(lr=0.001),\n",
    "                # optimizer=RMSprop(lr=0.001),\n",
    "                # optimizer=Adam(lr=0.001), #, rho=0.9, epsilon=1e-08, decay=0.0),\n",
    "                metrics =['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "    batch_size =batch_size,\n",
    "    epochs =epochs,\n",
    "    verbose =1,\n",
    "    validation_data =(X_test, y_test),\n",
    "    callbacks =[],  # reducelr_callback],\n",
    "    shuffle =True,\n",
    "    class_weight ={\n",
    "        0: 1,\n",
    "        1: 1,\n",
    "    }\n",
    "    )\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"AUC\", roc_auc_score(y_test[:, 1], predictions[:, 1]))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test[:, 1], predictions[:, 1])\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "\n",
    "    for i, xy in enumerate(zip(fpr, tpr)):\n",
    "        plt.gca().annotate(str(thresholds[i]), xy=xy, textcoords='data')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
