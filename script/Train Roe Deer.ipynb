{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from deepviz.guided_backprop import GuidedBackprop\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics.ranking import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deepviz.guided_backprop import GuidedBackprop\n",
    "\n",
    "try:\n",
    "    import keras\n",
    "\n",
    "    import keras.backend as K\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Activation\n",
    "    from keras.optimizers import RMSprop\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.optimizers import Adagrad\n",
    "    from keras.optimizers import SGD\n",
    "    from keras.callbacks import LambdaCallback, ReduceLROnPlateau, ModelCheckpoint\n",
    "    from keras.layers.core import Lambda\n",
    "    from keras.losses import categorical_crossentropy\n",
    "    import tensorflow as tf\n",
    "    from keras import regularizers\n",
    "\n",
    "except:\n",
    "    print(\"Keras not found\")\n",
    "    \n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def my_basename(path):\n",
    "    return os.path.splitext(os.path.split(path)[1])[0]\n",
    "\n",
    "file_dir=r'C:/Users/M-RAM/PycharmProjects/InternshipNaturalis/github_trait_geo_diverse_dl/trait-geo-diverse-dl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651\n",
      "811\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_76 (Dense)             (None, 50)                2100      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 25)                1275      \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 25)                650       \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 2)                 52        \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 4,727\n",
      "Trainable params: 4,727\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1242 samples, validate on 220 samples\n",
      "Epoch 1/500\n",
      "1242/1242 [==============================] - 1s 1ms/step - loss: 0.7121 - acc: 0.5749 - val_loss: 0.6591 - val_acc: 0.6727\n",
      "Epoch 2/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.5977 - acc: 0.7246 - val_loss: 0.5711 - val_acc: 0.7818\n",
      "Epoch 3/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.5040 - acc: 0.8341 - val_loss: 0.5186 - val_acc: 0.8045\n",
      "Epoch 4/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.4588 - acc: 0.8478 - val_loss: 0.4960 - val_acc: 0.8091\n",
      "Epoch 5/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.4342 - acc: 0.8527 - val_loss: 0.4784 - val_acc: 0.8045\n",
      "Epoch 6/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.4202 - acc: 0.8551 - val_loss: 0.4742 - val_acc: 0.8045\n",
      "Epoch 7/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.4097 - acc: 0.8527 - val_loss: 0.4712 - val_acc: 0.8045\n",
      "Epoch 8/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.4005 - acc: 0.8527 - val_loss: 0.4707 - val_acc: 0.8182\n",
      "Epoch 9/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.3938 - acc: 0.8591 - val_loss: 0.4684 - val_acc: 0.8136\n",
      "Epoch 10/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.3872 - acc: 0.8671 - val_loss: 0.4724 - val_acc: 0.8136\n",
      "Epoch 11/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.3814 - acc: 0.8655 - val_loss: 0.4665 - val_acc: 0.8227\n",
      "Epoch 12/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.3769 - acc: 0.8688 - val_loss: 0.4690 - val_acc: 0.8136\n",
      "Epoch 13/500\n",
      "1242/1242 [==============================] - 0s 28us/step - loss: 0.3699 - acc: 0.8720 - val_loss: 0.4642 - val_acc: 0.8182\n",
      "Epoch 14/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.3650 - acc: 0.8720 - val_loss: 0.4674 - val_acc: 0.8182\n",
      "Epoch 15/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.3590 - acc: 0.8792 - val_loss: 0.4613 - val_acc: 0.8273\n",
      "Epoch 16/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.3581 - acc: 0.8696 - val_loss: 0.4629 - val_acc: 0.8182\n",
      "Epoch 17/500\n",
      "1242/1242 [==============================] - 0s 29us/step - loss: 0.3528 - acc: 0.8800 - val_loss: 0.4620 - val_acc: 0.8318\n",
      "Epoch 18/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.3466 - acc: 0.8776 - val_loss: 0.4577 - val_acc: 0.8318\n",
      "Epoch 19/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.3393 - acc: 0.8808 - val_loss: 0.4612 - val_acc: 0.8318\n",
      "Epoch 20/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.3359 - acc: 0.8824 - val_loss: 0.4522 - val_acc: 0.8364\n",
      "Epoch 21/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.3324 - acc: 0.8849 - val_loss: 0.4497 - val_acc: 0.8409\n",
      "Epoch 22/500\n",
      "1242/1242 [==============================] - 0s 30us/step - loss: 0.3259 - acc: 0.8873 - val_loss: 0.4583 - val_acc: 0.8455\n",
      "Epoch 23/500\n",
      "1242/1242 [==============================] - 0s 29us/step - loss: 0.3228 - acc: 0.8929 - val_loss: 0.4570 - val_acc: 0.8364\n",
      "Epoch 24/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.3187 - acc: 0.8881 - val_loss: 0.4486 - val_acc: 0.8364\n",
      "Epoch 25/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.3128 - acc: 0.8897 - val_loss: 0.4606 - val_acc: 0.8273\n",
      "Epoch 26/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.3080 - acc: 0.8921 - val_loss: 0.4569 - val_acc: 0.8364\n",
      "Epoch 27/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.3024 - acc: 0.8945 - val_loss: 0.4619 - val_acc: 0.8227\n",
      "Epoch 28/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.3026 - acc: 0.8953 - val_loss: 0.4670 - val_acc: 0.8409\n",
      "Epoch 29/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2956 - acc: 0.8977 - val_loss: 0.4610 - val_acc: 0.8364\n",
      "Epoch 30/500\n",
      "1242/1242 [==============================] - 0s 29us/step - loss: 0.2902 - acc: 0.9026 - val_loss: 0.4731 - val_acc: 0.8227\n",
      "Epoch 31/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.2860 - acc: 0.9034 - val_loss: 0.4635 - val_acc: 0.8364\n",
      "Epoch 32/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2829 - acc: 0.9058 - val_loss: 0.4978 - val_acc: 0.8455\n",
      "Epoch 33/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.2882 - acc: 0.8994 - val_loss: 0.4703 - val_acc: 0.8273\n",
      "Epoch 34/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.2780 - acc: 0.9066 - val_loss: 0.4895 - val_acc: 0.8227\n",
      "Epoch 35/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2705 - acc: 0.9098 - val_loss: 0.4761 - val_acc: 0.8455\n",
      "Epoch 36/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2713 - acc: 0.9066 - val_loss: 0.4979 - val_acc: 0.8409\n",
      "Epoch 37/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.2646 - acc: 0.9155 - val_loss: 0.4837 - val_acc: 0.8409\n",
      "Epoch 38/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2563 - acc: 0.9155 - val_loss: 0.5037 - val_acc: 0.8409\n",
      "Epoch 39/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.2515 - acc: 0.9211 - val_loss: 0.4986 - val_acc: 0.8318\n",
      "Epoch 40/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.2534 - acc: 0.9195 - val_loss: 0.5161 - val_acc: 0.8364\n",
      "Epoch 41/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.2484 - acc: 0.9195 - val_loss: 0.5053 - val_acc: 0.8455\n",
      "Epoch 42/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.2441 - acc: 0.9259 - val_loss: 0.5201 - val_acc: 0.8409\n",
      "Epoch 43/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.2423 - acc: 0.9219 - val_loss: 0.5320 - val_acc: 0.8227\n",
      "Epoch 44/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2396 - acc: 0.9291 - val_loss: 0.5414 - val_acc: 0.8227\n",
      "Epoch 45/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2359 - acc: 0.9275 - val_loss: 0.5288 - val_acc: 0.8318\n",
      "Epoch 46/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2342 - acc: 0.9308 - val_loss: 0.5504 - val_acc: 0.8227\n",
      "Epoch 47/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2301 - acc: 0.9283 - val_loss: 0.6092 - val_acc: 0.8136\n",
      "Epoch 48/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.2306 - acc: 0.9243 - val_loss: 0.5562 - val_acc: 0.8364\n",
      "Epoch 49/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.2192 - acc: 0.9396 - val_loss: 0.5820 - val_acc: 0.8045\n",
      "Epoch 50/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.2188 - acc: 0.9396 - val_loss: 0.5948 - val_acc: 0.8364\n",
      "Epoch 51/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.2164 - acc: 0.9364 - val_loss: 0.6253 - val_acc: 0.8227\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2123 - acc: 0.9412 - val_loss: 0.6203 - val_acc: 0.8136\n",
      "Epoch 53/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2183 - acc: 0.9412 - val_loss: 0.6640 - val_acc: 0.8000\n",
      "Epoch 54/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2286 - acc: 0.9356 - val_loss: 0.6517 - val_acc: 0.8000\n",
      "Epoch 55/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.2053 - acc: 0.9444 - val_loss: 0.5990 - val_acc: 0.8182\n",
      "Epoch 56/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1989 - acc: 0.9493 - val_loss: 0.6446 - val_acc: 0.8045\n",
      "Epoch 57/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1956 - acc: 0.9485 - val_loss: 0.6624 - val_acc: 0.8045\n",
      "Epoch 58/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1920 - acc: 0.9533 - val_loss: 0.6719 - val_acc: 0.8136\n",
      "Epoch 59/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1903 - acc: 0.9533 - val_loss: 0.6839 - val_acc: 0.8045\n",
      "Epoch 60/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1904 - acc: 0.9517 - val_loss: 0.7018 - val_acc: 0.8136\n",
      "Epoch 61/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1870 - acc: 0.9517 - val_loss: 0.7086 - val_acc: 0.8091\n",
      "Epoch 62/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.1853 - acc: 0.9573 - val_loss: 0.7374 - val_acc: 0.8136\n",
      "Epoch 63/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.1818 - acc: 0.9541 - val_loss: 0.7141 - val_acc: 0.8091\n",
      "Epoch 64/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.1786 - acc: 0.9557 - val_loss: 0.7227 - val_acc: 0.8000\n",
      "Epoch 65/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1822 - acc: 0.9485 - val_loss: 0.7543 - val_acc: 0.8045\n",
      "Epoch 66/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.2035 - acc: 0.9452 - val_loss: 0.7283 - val_acc: 0.7909\n",
      "Epoch 67/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1783 - acc: 0.9509 - val_loss: 0.7637 - val_acc: 0.7909\n",
      "Epoch 68/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1724 - acc: 0.9549 - val_loss: 0.7494 - val_acc: 0.7955\n",
      "Epoch 69/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1854 - acc: 0.9517 - val_loss: 0.7674 - val_acc: 0.7864\n",
      "Epoch 70/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1776 - acc: 0.9509 - val_loss: 0.7815 - val_acc: 0.7909\n",
      "Epoch 71/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1705 - acc: 0.9581 - val_loss: 0.7616 - val_acc: 0.8045\n",
      "Epoch 72/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1613 - acc: 0.9597 - val_loss: 0.7701 - val_acc: 0.8136\n",
      "Epoch 73/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1703 - acc: 0.9630 - val_loss: 0.8364 - val_acc: 0.7864\n",
      "Epoch 74/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1603 - acc: 0.9630 - val_loss: 0.7929 - val_acc: 0.8000\n",
      "Epoch 75/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1547 - acc: 0.9654 - val_loss: 0.8063 - val_acc: 0.7955\n",
      "Epoch 76/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1600 - acc: 0.9646 - val_loss: 0.8088 - val_acc: 0.7909\n",
      "Epoch 77/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1605 - acc: 0.9605 - val_loss: 0.8121 - val_acc: 0.8000\n",
      "Epoch 78/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1560 - acc: 0.9581 - val_loss: 0.8584 - val_acc: 0.7818\n",
      "Epoch 79/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1513 - acc: 0.9646 - val_loss: 0.8749 - val_acc: 0.8000\n",
      "Epoch 80/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1616 - acc: 0.9622 - val_loss: 0.9250 - val_acc: 0.7682\n",
      "Epoch 81/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1607 - acc: 0.9630 - val_loss: 0.8770 - val_acc: 0.8000\n",
      "Epoch 82/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1442 - acc: 0.9702 - val_loss: 0.9009 - val_acc: 0.7909\n",
      "Epoch 83/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1498 - acc: 0.9678 - val_loss: 0.9049 - val_acc: 0.8000\n",
      "Epoch 84/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1420 - acc: 0.9678 - val_loss: 0.9264 - val_acc: 0.7773\n",
      "Epoch 85/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1352 - acc: 0.9758 - val_loss: 0.9026 - val_acc: 0.8045\n",
      "Epoch 86/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1357 - acc: 0.9767 - val_loss: 0.9688 - val_acc: 0.7909\n",
      "Epoch 87/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1351 - acc: 0.9726 - val_loss: 0.9263 - val_acc: 0.7955\n",
      "Epoch 88/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1321 - acc: 0.9783 - val_loss: 0.9427 - val_acc: 0.8091\n",
      "Epoch 89/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1326 - acc: 0.9767 - val_loss: 0.9608 - val_acc: 0.7955\n",
      "Epoch 90/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1264 - acc: 0.9791 - val_loss: 0.9412 - val_acc: 0.7909\n",
      "Epoch 91/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1268 - acc: 0.9767 - val_loss: 0.9647 - val_acc: 0.8045\n",
      "Epoch 92/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1258 - acc: 0.9783 - val_loss: 0.9655 - val_acc: 0.7955\n",
      "Epoch 93/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1306 - acc: 0.9750 - val_loss: 1.0272 - val_acc: 0.7636\n",
      "Epoch 94/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1305 - acc: 0.9750 - val_loss: 1.0228 - val_acc: 0.7818\n",
      "Epoch 95/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1264 - acc: 0.9742 - val_loss: 1.0398 - val_acc: 0.7818\n",
      "Epoch 96/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1238 - acc: 0.9799 - val_loss: 1.0433 - val_acc: 0.7727\n",
      "Epoch 97/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1250 - acc: 0.9791 - val_loss: 1.0315 - val_acc: 0.7955\n",
      "Epoch 98/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.1211 - acc: 0.9823 - val_loss: 1.0357 - val_acc: 0.7909\n",
      "Epoch 99/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1347 - acc: 0.9783 - val_loss: 1.0582 - val_acc: 0.7682\n",
      "Epoch 100/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1146 - acc: 0.9871 - val_loss: 1.0402 - val_acc: 0.8091\n",
      "Epoch 101/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1130 - acc: 0.9831 - val_loss: 1.0596 - val_acc: 0.7727\n",
      "Epoch 102/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.1122 - acc: 0.9831 - val_loss: 1.0735 - val_acc: 0.7818\n",
      "Epoch 103/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1153 - acc: 0.9799 - val_loss: 1.0939 - val_acc: 0.7909\n",
      "Epoch 104/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1101 - acc: 0.9847 - val_loss: 1.0851 - val_acc: 0.7909\n",
      "Epoch 105/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1074 - acc: 0.9871 - val_loss: 1.1106 - val_acc: 0.7818\n",
      "Epoch 106/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1066 - acc: 0.9855 - val_loss: 1.1405 - val_acc: 0.7909\n",
      "Epoch 107/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1106 - acc: 0.9847 - val_loss: 1.1516 - val_acc: 0.7727\n",
      "Epoch 108/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1146 - acc: 0.9823 - val_loss: 1.1539 - val_acc: 0.7864\n",
      "Epoch 109/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1201 - acc: 0.9855 - val_loss: 1.1815 - val_acc: 0.7864\n",
      "Epoch 110/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1440 - acc: 0.9726 - val_loss: 1.1086 - val_acc: 0.7591\n",
      "Epoch 111/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.1503 - acc: 0.9654 - val_loss: 1.1697 - val_acc: 0.7545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1314 - acc: 0.9750 - val_loss: 1.1724 - val_acc: 0.7864\n",
      "Epoch 113/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1241 - acc: 0.9750 - val_loss: 1.0652 - val_acc: 0.7955\n",
      "Epoch 114/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1231 - acc: 0.9831 - val_loss: 1.1383 - val_acc: 0.7864\n",
      "Epoch 115/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.1647 - acc: 0.9670 - val_loss: 1.1785 - val_acc: 0.7864\n",
      "Epoch 116/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1536 - acc: 0.9638 - val_loss: 1.1809 - val_acc: 0.7591\n",
      "Epoch 117/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1436 - acc: 0.9622 - val_loss: 1.1316 - val_acc: 0.7773\n",
      "Epoch 118/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1247 - acc: 0.9742 - val_loss: 1.1104 - val_acc: 0.8000\n",
      "Epoch 119/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1183 - acc: 0.9855 - val_loss: 1.1314 - val_acc: 0.7818\n",
      "Epoch 120/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1126 - acc: 0.9847 - val_loss: 1.1492 - val_acc: 0.7864\n",
      "Epoch 121/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.1018 - acc: 0.9928 - val_loss: 1.1687 - val_acc: 0.7909\n",
      "Epoch 122/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1031 - acc: 0.9887 - val_loss: 1.1671 - val_acc: 0.7864\n",
      "Epoch 123/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1017 - acc: 0.9911 - val_loss: 1.1660 - val_acc: 0.7909\n",
      "Epoch 124/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1040 - acc: 0.9879 - val_loss: 1.1618 - val_acc: 0.7955\n",
      "Epoch 125/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0970 - acc: 0.9895 - val_loss: 1.2251 - val_acc: 0.7818\n",
      "Epoch 126/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0978 - acc: 0.9911 - val_loss: 1.1991 - val_acc: 0.7818\n",
      "Epoch 127/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.1026 - acc: 0.9871 - val_loss: 1.2159 - val_acc: 0.7955\n",
      "Epoch 128/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0980 - acc: 0.9895 - val_loss: 1.2420 - val_acc: 0.7682\n",
      "Epoch 129/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0961 - acc: 0.9928 - val_loss: 1.2441 - val_acc: 0.7955\n",
      "Epoch 130/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0953 - acc: 0.9936 - val_loss: 1.2676 - val_acc: 0.7773\n",
      "Epoch 131/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0980 - acc: 0.9903 - val_loss: 1.2821 - val_acc: 0.7773\n",
      "Epoch 132/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0962 - acc: 0.9911 - val_loss: 1.2860 - val_acc: 0.7636\n",
      "Epoch 133/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0964 - acc: 0.9895 - val_loss: 1.2781 - val_acc: 0.7864\n",
      "Epoch 134/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0979 - acc: 0.9895 - val_loss: 1.2836 - val_acc: 0.7636\n",
      "Epoch 135/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0996 - acc: 0.9928 - val_loss: 1.3225 - val_acc: 0.7773\n",
      "Epoch 136/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0925 - acc: 0.9911 - val_loss: 1.2889 - val_acc: 0.7909\n",
      "Epoch 137/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0904 - acc: 0.9903 - val_loss: 1.3212 - val_acc: 0.7773\n",
      "Epoch 138/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0901 - acc: 0.9952 - val_loss: 1.3171 - val_acc: 0.7773\n",
      "Epoch 139/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0963 - acc: 0.9903 - val_loss: 1.2925 - val_acc: 0.7727\n",
      "Epoch 140/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0943 - acc: 0.9944 - val_loss: 1.3206 - val_acc: 0.7773\n",
      "Epoch 141/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0883 - acc: 0.9952 - val_loss: 1.3405 - val_acc: 0.7818\n",
      "Epoch 142/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0871 - acc: 0.9960 - val_loss: 1.3421 - val_acc: 0.7864\n",
      "Epoch 143/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0876 - acc: 0.9952 - val_loss: 1.3584 - val_acc: 0.7727\n",
      "Epoch 144/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0879 - acc: 0.9944 - val_loss: 1.3685 - val_acc: 0.7818\n",
      "Epoch 145/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0875 - acc: 0.9960 - val_loss: 1.3349 - val_acc: 0.7864\n",
      "Epoch 146/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0855 - acc: 0.9952 - val_loss: 1.4341 - val_acc: 0.7682\n",
      "Epoch 147/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0867 - acc: 0.9976 - val_loss: 1.3855 - val_acc: 0.7773\n",
      "Epoch 148/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0987 - acc: 0.9911 - val_loss: 1.3827 - val_acc: 0.7773\n",
      "Epoch 149/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1011 - acc: 0.9903 - val_loss: 1.3835 - val_acc: 0.7864\n",
      "Epoch 150/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0926 - acc: 0.9928 - val_loss: 1.3678 - val_acc: 0.7909\n",
      "Epoch 151/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0995 - acc: 0.9911 - val_loss: 1.4136 - val_acc: 0.7727\n",
      "Epoch 152/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0917 - acc: 0.9919 - val_loss: 1.3914 - val_acc: 0.7500\n",
      "Epoch 153/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0964 - acc: 0.9887 - val_loss: 1.4304 - val_acc: 0.7682\n",
      "Epoch 154/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1020 - acc: 0.9887 - val_loss: 1.4925 - val_acc: 0.7727\n",
      "Epoch 155/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1080 - acc: 0.9871 - val_loss: 1.5436 - val_acc: 0.7500\n",
      "Epoch 156/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1310 - acc: 0.9791 - val_loss: 1.5047 - val_acc: 0.7591\n",
      "Epoch 157/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1182 - acc: 0.9831 - val_loss: 1.3870 - val_acc: 0.7864\n",
      "Epoch 158/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0956 - acc: 0.9887 - val_loss: 1.4205 - val_acc: 0.7682\n",
      "Epoch 159/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0883 - acc: 0.9936 - val_loss: 1.4287 - val_acc: 0.7773\n",
      "Epoch 160/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0860 - acc: 0.9944 - val_loss: 1.4417 - val_acc: 0.7773\n",
      "Epoch 161/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0866 - acc: 0.9952 - val_loss: 1.4626 - val_acc: 0.7727\n",
      "Epoch 162/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0853 - acc: 0.9936 - val_loss: 1.4539 - val_acc: 0.7773\n",
      "Epoch 163/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0855 - acc: 0.9960 - val_loss: 1.4291 - val_acc: 0.7682\n",
      "Epoch 164/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0820 - acc: 0.9968 - val_loss: 1.4270 - val_acc: 0.7727\n",
      "Epoch 165/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0840 - acc: 0.9960 - val_loss: 1.4682 - val_acc: 0.7773\n",
      "Epoch 166/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0837 - acc: 0.9984 - val_loss: 1.4685 - val_acc: 0.7682\n",
      "Epoch 167/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0821 - acc: 0.9976 - val_loss: 1.4323 - val_acc: 0.7727\n",
      "Epoch 168/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0836 - acc: 0.9960 - val_loss: 1.4772 - val_acc: 0.7727\n",
      "Epoch 169/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0849 - acc: 0.9976 - val_loss: 1.4405 - val_acc: 0.7727\n",
      "Epoch 170/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0850 - acc: 0.9960 - val_loss: 1.4327 - val_acc: 0.7818\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0852 - acc: 0.9952 - val_loss: 1.5006 - val_acc: 0.7636\n",
      "Epoch 172/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0835 - acc: 0.9952 - val_loss: 1.4930 - val_acc: 0.7818\n",
      "Epoch 173/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0942 - acc: 0.9928 - val_loss: 1.5252 - val_acc: 0.7636\n",
      "Epoch 174/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1307 - acc: 0.9887 - val_loss: 1.4868 - val_acc: 0.7591\n",
      "Epoch 175/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1274 - acc: 0.9839 - val_loss: 1.6243 - val_acc: 0.7591\n",
      "Epoch 176/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1079 - acc: 0.9863 - val_loss: 1.4618 - val_acc: 0.7818\n",
      "Epoch 177/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1169 - acc: 0.9839 - val_loss: 1.7055 - val_acc: 0.7500\n",
      "Epoch 178/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1512 - acc: 0.9767 - val_loss: 1.5935 - val_acc: 0.7636\n",
      "Epoch 179/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0999 - acc: 0.9911 - val_loss: 1.4330 - val_acc: 0.7864\n",
      "Epoch 180/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0980 - acc: 0.9919 - val_loss: 1.4538 - val_acc: 0.7955\n",
      "Epoch 181/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0990 - acc: 0.9879 - val_loss: 1.4854 - val_acc: 0.7591\n",
      "Epoch 182/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0866 - acc: 0.9952 - val_loss: 1.5040 - val_acc: 0.7636\n",
      "Epoch 183/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0856 - acc: 0.9903 - val_loss: 1.4898 - val_acc: 0.7682\n",
      "Epoch 184/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0810 - acc: 0.9968 - val_loss: 1.4696 - val_acc: 0.7727\n",
      "Epoch 185/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0779 - acc: 0.9968 - val_loss: 1.4991 - val_acc: 0.7727\n",
      "Epoch 186/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0784 - acc: 0.9960 - val_loss: 1.4996 - val_acc: 0.7727\n",
      "Epoch 187/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0780 - acc: 0.9976 - val_loss: 1.4895 - val_acc: 0.7727\n",
      "Epoch 188/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0777 - acc: 0.9960 - val_loss: 1.5430 - val_acc: 0.7682\n",
      "Epoch 189/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0790 - acc: 0.9976 - val_loss: 1.5550 - val_acc: 0.7773\n",
      "Epoch 190/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0780 - acc: 0.9968 - val_loss: 1.5348 - val_acc: 0.7636\n",
      "Epoch 191/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0766 - acc: 0.9976 - val_loss: 1.5538 - val_acc: 0.7864\n",
      "Epoch 192/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0804 - acc: 0.9976 - val_loss: 1.5277 - val_acc: 0.7727\n",
      "Epoch 193/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0781 - acc: 0.9968 - val_loss: 1.5235 - val_acc: 0.7727\n",
      "Epoch 194/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0792 - acc: 0.9968 - val_loss: 1.5668 - val_acc: 0.7773\n",
      "Epoch 195/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0775 - acc: 0.9960 - val_loss: 1.5523 - val_acc: 0.7773\n",
      "Epoch 196/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0806 - acc: 0.9936 - val_loss: 1.5335 - val_acc: 0.7727\n",
      "Epoch 197/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0779 - acc: 0.9960 - val_loss: 1.5476 - val_acc: 0.7682\n",
      "Epoch 198/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0793 - acc: 0.9968 - val_loss: 1.5506 - val_acc: 0.7818\n",
      "Epoch 199/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0770 - acc: 0.9968 - val_loss: 1.5428 - val_acc: 0.7818\n",
      "Epoch 200/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0774 - acc: 0.9968 - val_loss: 1.5652 - val_acc: 0.7818\n",
      "Epoch 201/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0774 - acc: 0.9984 - val_loss: 1.5440 - val_acc: 0.7682\n",
      "Epoch 202/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0766 - acc: 0.9976 - val_loss: 1.5831 - val_acc: 0.7773\n",
      "Epoch 203/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0767 - acc: 0.9960 - val_loss: 1.5775 - val_acc: 0.7818\n",
      "Epoch 204/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0755 - acc: 0.9976 - val_loss: 1.5631 - val_acc: 0.7682\n",
      "Epoch 205/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0781 - acc: 0.9960 - val_loss: 1.5781 - val_acc: 0.7864\n",
      "Epoch 206/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0762 - acc: 0.9960 - val_loss: 1.5995 - val_acc: 0.7727\n",
      "Epoch 207/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0749 - acc: 0.9984 - val_loss: 1.5677 - val_acc: 0.7773\n",
      "Epoch 208/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0757 - acc: 0.9976 - val_loss: 1.5982 - val_acc: 0.7773\n",
      "Epoch 209/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0745 - acc: 0.9968 - val_loss: 1.5882 - val_acc: 0.7909\n",
      "Epoch 210/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0761 - acc: 0.9976 - val_loss: 1.6163 - val_acc: 0.7636\n",
      "Epoch 211/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0760 - acc: 0.9968 - val_loss: 1.5861 - val_acc: 0.7773\n",
      "Epoch 212/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0745 - acc: 0.9976 - val_loss: 1.6067 - val_acc: 0.7682\n",
      "Epoch 213/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0749 - acc: 0.9984 - val_loss: 1.5889 - val_acc: 0.7773\n",
      "Epoch 214/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0753 - acc: 0.9984 - val_loss: 1.5890 - val_acc: 0.7773\n",
      "Epoch 215/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0729 - acc: 0.9984 - val_loss: 1.5821 - val_acc: 0.7818\n",
      "Epoch 216/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0757 - acc: 0.9968 - val_loss: 1.5932 - val_acc: 0.7818\n",
      "Epoch 217/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0765 - acc: 0.9984 - val_loss: 1.5773 - val_acc: 0.7636\n",
      "Epoch 218/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0775 - acc: 0.9968 - val_loss: 1.6258 - val_acc: 0.7727\n",
      "Epoch 219/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0788 - acc: 0.9976 - val_loss: 1.6488 - val_acc: 0.7909\n",
      "Epoch 220/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0790 - acc: 0.9960 - val_loss: 1.5565 - val_acc: 0.7773\n",
      "Epoch 221/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0798 - acc: 0.9944 - val_loss: 1.6074 - val_acc: 0.7727\n",
      "Epoch 222/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0747 - acc: 0.9960 - val_loss: 1.6097 - val_acc: 0.7909\n",
      "Epoch 223/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0746 - acc: 0.9968 - val_loss: 1.6228 - val_acc: 0.7727\n",
      "Epoch 224/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0736 - acc: 0.9984 - val_loss: 1.6116 - val_acc: 0.7727\n",
      "Epoch 225/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0726 - acc: 0.9976 - val_loss: 1.6479 - val_acc: 0.7909\n",
      "Epoch 226/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0748 - acc: 0.9968 - val_loss: 1.6267 - val_acc: 0.7773\n",
      "Epoch 227/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0748 - acc: 0.9984 - val_loss: 1.6351 - val_acc: 0.7727\n",
      "Epoch 228/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0762 - acc: 0.9976 - val_loss: 1.6524 - val_acc: 0.7773\n",
      "Epoch 229/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0782 - acc: 0.9960 - val_loss: 1.6254 - val_acc: 0.7727\n",
      "Epoch 230/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0749 - acc: 0.9968 - val_loss: 1.6223 - val_acc: 0.7864\n",
      "Epoch 231/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0745 - acc: 0.9976 - val_loss: 1.6393 - val_acc: 0.7773\n",
      "Epoch 232/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0750 - acc: 0.9976 - val_loss: 1.6340 - val_acc: 0.7682\n",
      "Epoch 233/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0733 - acc: 0.9976 - val_loss: 1.6006 - val_acc: 0.7864\n",
      "Epoch 234/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0724 - acc: 0.9976 - val_loss: 1.6311 - val_acc: 0.7682\n",
      "Epoch 235/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0747 - acc: 0.9976 - val_loss: 1.6633 - val_acc: 0.7818\n",
      "Epoch 236/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0744 - acc: 0.9960 - val_loss: 1.6420 - val_acc: 0.7773\n",
      "Epoch 237/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0738 - acc: 0.9968 - val_loss: 1.6739 - val_acc: 0.7864\n",
      "Epoch 238/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0749 - acc: 0.9968 - val_loss: 1.6238 - val_acc: 0.7818\n",
      "Epoch 239/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0739 - acc: 0.9968 - val_loss: 1.6826 - val_acc: 0.7818\n",
      "Epoch 240/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0750 - acc: 0.9960 - val_loss: 1.6387 - val_acc: 0.7864\n",
      "Epoch 241/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0716 - acc: 0.9976 - val_loss: 1.6717 - val_acc: 0.7909\n",
      "Epoch 242/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0738 - acc: 0.9968 - val_loss: 1.6581 - val_acc: 0.7682\n",
      "Epoch 243/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0801 - acc: 0.9976 - val_loss: 1.6732 - val_acc: 0.7727\n",
      "Epoch 244/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0786 - acc: 0.9960 - val_loss: 1.6907 - val_acc: 0.7864\n",
      "Epoch 245/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0812 - acc: 0.9936 - val_loss: 1.6624 - val_acc: 0.7818\n",
      "Epoch 246/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0829 - acc: 0.9944 - val_loss: 1.7320 - val_acc: 0.7727\n",
      "Epoch 247/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0829 - acc: 0.9952 - val_loss: 1.7315 - val_acc: 0.7727\n",
      "Epoch 248/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0815 - acc: 0.9952 - val_loss: 1.5991 - val_acc: 0.7955\n",
      "Epoch 249/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1079 - acc: 0.9871 - val_loss: 1.8506 - val_acc: 0.7545\n",
      "Epoch 250/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1853 - acc: 0.9791 - val_loss: 1.7509 - val_acc: 0.7727\n",
      "Epoch 251/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.2307 - acc: 0.9638 - val_loss: 1.5167 - val_acc: 0.7864\n",
      "Epoch 252/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1916 - acc: 0.9614 - val_loss: 1.7683 - val_acc: 0.7636\n",
      "Epoch 253/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1576 - acc: 0.9702 - val_loss: 1.6241 - val_acc: 0.7909\n",
      "Epoch 254/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1502 - acc: 0.9742 - val_loss: 1.7085 - val_acc: 0.7636\n",
      "Epoch 255/500\n",
      "1242/1242 [==============================] - 0s 20us/step - loss: 0.1130 - acc: 0.9807 - val_loss: 1.6393 - val_acc: 0.7591\n",
      "Epoch 256/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1029 - acc: 0.9887 - val_loss: 1.5496 - val_acc: 0.7636\n",
      "Epoch 257/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0965 - acc: 0.9863 - val_loss: 1.5204 - val_acc: 0.7727\n",
      "Epoch 258/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0907 - acc: 0.9911 - val_loss: 1.5486 - val_acc: 0.7591\n",
      "Epoch 259/500\n",
      "1242/1242 [==============================] - 0s 20us/step - loss: 0.0859 - acc: 0.9919 - val_loss: 1.5019 - val_acc: 0.7818\n",
      "Epoch 260/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0786 - acc: 0.9976 - val_loss: 1.5203 - val_acc: 0.7727\n",
      "Epoch 261/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0769 - acc: 0.9976 - val_loss: 1.4999 - val_acc: 0.7773\n",
      "Epoch 262/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0753 - acc: 0.9968 - val_loss: 1.5502 - val_acc: 0.7727\n",
      "Epoch 263/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0744 - acc: 0.9976 - val_loss: 1.5448 - val_acc: 0.7682\n",
      "Epoch 264/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0742 - acc: 0.9976 - val_loss: 1.5660 - val_acc: 0.7727\n",
      "Epoch 265/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0736 - acc: 0.9976 - val_loss: 1.5658 - val_acc: 0.7773\n",
      "Epoch 266/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0723 - acc: 0.9976 - val_loss: 1.5823 - val_acc: 0.7818\n",
      "Epoch 267/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0728 - acc: 0.9976 - val_loss: 1.5703 - val_acc: 0.7727\n",
      "Epoch 268/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0742 - acc: 0.9976 - val_loss: 1.6072 - val_acc: 0.7636\n",
      "Epoch 269/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0724 - acc: 0.9984 - val_loss: 1.6056 - val_acc: 0.7773\n",
      "Epoch 270/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0741 - acc: 0.9968 - val_loss: 1.5769 - val_acc: 0.7773\n",
      "Epoch 271/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0723 - acc: 0.9976 - val_loss: 1.6098 - val_acc: 0.7773\n",
      "Epoch 272/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0720 - acc: 0.9984 - val_loss: 1.5986 - val_acc: 0.7773\n",
      "Epoch 273/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0746 - acc: 0.9984 - val_loss: 1.6112 - val_acc: 0.7773\n",
      "Epoch 274/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0723 - acc: 0.9968 - val_loss: 1.6298 - val_acc: 0.7818\n",
      "Epoch 275/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0740 - acc: 0.9960 - val_loss: 1.6266 - val_acc: 0.7727\n",
      "Epoch 276/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0724 - acc: 0.9976 - val_loss: 1.6184 - val_acc: 0.7773\n",
      "Epoch 277/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0714 - acc: 0.9976 - val_loss: 1.6328 - val_acc: 0.7818\n",
      "Epoch 278/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0726 - acc: 0.9976 - val_loss: 1.6372 - val_acc: 0.7864\n",
      "Epoch 279/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0736 - acc: 0.9968 - val_loss: 1.5972 - val_acc: 0.7727\n",
      "Epoch 280/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0729 - acc: 0.9968 - val_loss: 1.6260 - val_acc: 0.7773\n",
      "Epoch 281/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0724 - acc: 0.9968 - val_loss: 1.6459 - val_acc: 0.7864\n",
      "Epoch 282/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0717 - acc: 0.9984 - val_loss: 1.6562 - val_acc: 0.7773\n",
      "Epoch 283/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0745 - acc: 0.9984 - val_loss: 1.6314 - val_acc: 0.7864\n",
      "Epoch 284/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0718 - acc: 0.9968 - val_loss: 1.6354 - val_acc: 0.7773\n",
      "Epoch 285/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0729 - acc: 0.9976 - val_loss: 1.6247 - val_acc: 0.7818\n",
      "Epoch 286/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0701 - acc: 0.9984 - val_loss: 1.6528 - val_acc: 0.7909\n",
      "Epoch 287/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0717 - acc: 0.9984 - val_loss: 1.6613 - val_acc: 0.7773\n",
      "Epoch 288/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0706 - acc: 0.9968 - val_loss: 1.6246 - val_acc: 0.7818\n",
      "Epoch 289/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0716 - acc: 0.9976 - val_loss: 1.6542 - val_acc: 0.7864\n",
      "Epoch 290/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0702 - acc: 0.9984 - val_loss: 1.6331 - val_acc: 0.7727\n",
      "Epoch 291/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0717 - acc: 0.9976 - val_loss: 1.6604 - val_acc: 0.7909\n",
      "Epoch 292/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0721 - acc: 0.9952 - val_loss: 1.6644 - val_acc: 0.7909\n",
      "Epoch 293/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0716 - acc: 0.9984 - val_loss: 1.6376 - val_acc: 0.7682\n",
      "Epoch 294/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0716 - acc: 0.9976 - val_loss: 1.6681 - val_acc: 0.7864\n",
      "Epoch 295/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0722 - acc: 0.9976 - val_loss: 1.6422 - val_acc: 0.7864\n",
      "Epoch 296/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0717 - acc: 0.9984 - val_loss: 1.6826 - val_acc: 0.7909\n",
      "Epoch 297/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0746 - acc: 0.9968 - val_loss: 1.6640 - val_acc: 0.7636\n",
      "Epoch 298/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0711 - acc: 0.9968 - val_loss: 1.6566 - val_acc: 0.7818\n",
      "Epoch 299/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0703 - acc: 0.9984 - val_loss: 1.6468 - val_acc: 0.7818\n",
      "Epoch 300/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0703 - acc: 0.9984 - val_loss: 1.6787 - val_acc: 0.7909\n",
      "Epoch 301/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0704 - acc: 0.9976 - val_loss: 1.6716 - val_acc: 0.7864\n",
      "Epoch 302/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0696 - acc: 0.9984 - val_loss: 1.6604 - val_acc: 0.7864\n",
      "Epoch 303/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0705 - acc: 0.9976 - val_loss: 1.6804 - val_acc: 0.7909\n",
      "Epoch 304/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0705 - acc: 0.9976 - val_loss: 1.6769 - val_acc: 0.7864\n",
      "Epoch 305/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0696 - acc: 0.9984 - val_loss: 1.6757 - val_acc: 0.7773\n",
      "Epoch 306/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0701 - acc: 0.9984 - val_loss: 1.6790 - val_acc: 0.7909\n",
      "Epoch 307/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0728 - acc: 0.9976 - val_loss: 1.7213 - val_acc: 0.7909\n",
      "Epoch 308/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0728 - acc: 0.9976 - val_loss: 1.6625 - val_acc: 0.7773\n",
      "Epoch 309/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0721 - acc: 0.9960 - val_loss: 1.6700 - val_acc: 0.7773\n",
      "Epoch 310/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0709 - acc: 0.9952 - val_loss: 1.7054 - val_acc: 0.7682\n",
      "Epoch 311/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0743 - acc: 0.9952 - val_loss: 1.7102 - val_acc: 0.7864\n",
      "Epoch 312/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0749 - acc: 0.9968 - val_loss: 1.6866 - val_acc: 0.7909\n",
      "Epoch 313/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0763 - acc: 0.9944 - val_loss: 1.7051 - val_acc: 0.7773\n",
      "Epoch 314/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0790 - acc: 0.9928 - val_loss: 1.6553 - val_acc: 0.7727\n",
      "Epoch 315/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0827 - acc: 0.9928 - val_loss: 1.6675 - val_acc: 0.7864\n",
      "Epoch 316/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0802 - acc: 0.9919 - val_loss: 1.6267 - val_acc: 0.7818\n",
      "Epoch 317/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0737 - acc: 0.9968 - val_loss: 1.6627 - val_acc: 0.7591\n",
      "Epoch 318/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0757 - acc: 0.9952 - val_loss: 1.7399 - val_acc: 0.7727\n",
      "Epoch 319/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0765 - acc: 0.9936 - val_loss: 1.6849 - val_acc: 0.7682\n",
      "Epoch 320/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0761 - acc: 0.9952 - val_loss: 1.7513 - val_acc: 0.7773\n",
      "Epoch 321/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0711 - acc: 0.9984 - val_loss: 1.6894 - val_acc: 0.7818\n",
      "Epoch 322/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0735 - acc: 0.9968 - val_loss: 1.6319 - val_acc: 0.7727\n",
      "Epoch 323/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0690 - acc: 0.9984 - val_loss: 1.6506 - val_acc: 0.7773\n",
      "Epoch 324/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0682 - acc: 0.9976 - val_loss: 1.6350 - val_acc: 0.7864\n",
      "Epoch 325/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0684 - acc: 0.9976 - val_loss: 1.6452 - val_acc: 0.7864\n",
      "Epoch 326/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0690 - acc: 0.9984 - val_loss: 1.6440 - val_acc: 0.7773\n",
      "Epoch 327/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0675 - acc: 0.9976 - val_loss: 1.6683 - val_acc: 0.7773\n",
      "Epoch 328/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0694 - acc: 0.9984 - val_loss: 1.6568 - val_acc: 0.7818\n",
      "Epoch 329/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0701 - acc: 0.9984 - val_loss: 1.6687 - val_acc: 0.7864\n",
      "Epoch 330/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0672 - acc: 0.9984 - val_loss: 1.6933 - val_acc: 0.7818\n",
      "Epoch 331/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0720 - acc: 0.9968 - val_loss: 1.6913 - val_acc: 0.7818\n",
      "Epoch 332/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0692 - acc: 0.9968 - val_loss: 1.6953 - val_acc: 0.7864\n",
      "Epoch 333/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0698 - acc: 0.9976 - val_loss: 1.7076 - val_acc: 0.7773\n",
      "Epoch 334/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0705 - acc: 0.9968 - val_loss: 1.7057 - val_acc: 0.7818\n",
      "Epoch 335/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0688 - acc: 0.9960 - val_loss: 1.7103 - val_acc: 0.7818\n",
      "Epoch 336/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0692 - acc: 0.9976 - val_loss: 1.7002 - val_acc: 0.7682\n",
      "Epoch 337/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0700 - acc: 0.9968 - val_loss: 1.7130 - val_acc: 0.7727\n",
      "Epoch 338/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0671 - acc: 0.9984 - val_loss: 1.6974 - val_acc: 0.7818\n",
      "Epoch 339/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0705 - acc: 0.9976 - val_loss: 1.7613 - val_acc: 0.7818\n",
      "Epoch 340/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0692 - acc: 0.9984 - val_loss: 1.6870 - val_acc: 0.7773\n",
      "Epoch 341/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0685 - acc: 0.9984 - val_loss: 1.7294 - val_acc: 0.7727\n",
      "Epoch 342/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0680 - acc: 0.9968 - val_loss: 1.7146 - val_acc: 0.7818\n",
      "Epoch 343/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0682 - acc: 0.9984 - val_loss: 1.7229 - val_acc: 0.7818\n",
      "Epoch 344/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0671 - acc: 0.9976 - val_loss: 1.7294 - val_acc: 0.7727\n",
      "Epoch 345/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0676 - acc: 0.9976 - val_loss: 1.7212 - val_acc: 0.7727\n",
      "Epoch 346/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0685 - acc: 0.9968 - val_loss: 1.7521 - val_acc: 0.7773\n",
      "Epoch 347/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0711 - acc: 0.9968 - val_loss: 1.6610 - val_acc: 0.7773\n",
      "Epoch 348/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0755 - acc: 0.9960 - val_loss: 1.6467 - val_acc: 0.7682\n",
      "Epoch 349/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0710 - acc: 0.9976 - val_loss: 1.7159 - val_acc: 0.7773\n",
      "Epoch 350/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0851 - acc: 0.9952 - val_loss: 1.7005 - val_acc: 0.7727\n",
      "Epoch 351/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0863 - acc: 0.9911 - val_loss: 1.7294 - val_acc: 0.7682\n",
      "Epoch 352/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1014 - acc: 0.9863 - val_loss: 1.6126 - val_acc: 0.7636\n",
      "Epoch 353/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1042 - acc: 0.9879 - val_loss: 1.7070 - val_acc: 0.7636\n",
      "Epoch 354/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0888 - acc: 0.9903 - val_loss: 1.7090 - val_acc: 0.7591\n",
      "Epoch 355/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0896 - acc: 0.9911 - val_loss: 1.6068 - val_acc: 0.7727\n",
      "Epoch 356/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0837 - acc: 0.9903 - val_loss: 1.5589 - val_acc: 0.7682\n",
      "Epoch 357/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0998 - acc: 0.9847 - val_loss: 1.6255 - val_acc: 0.7818\n",
      "Epoch 358/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0985 - acc: 0.9871 - val_loss: 1.7168 - val_acc: 0.7682\n",
      "Epoch 359/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0819 - acc: 0.9911 - val_loss: 1.6578 - val_acc: 0.7682\n",
      "Epoch 360/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0825 - acc: 0.9944 - val_loss: 1.8511 - val_acc: 0.7455\n",
      "Epoch 361/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0939 - acc: 0.9879 - val_loss: 1.7093 - val_acc: 0.7773\n",
      "Epoch 362/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0885 - acc: 0.9919 - val_loss: 1.8248 - val_acc: 0.7636\n",
      "Epoch 363/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.1080 - acc: 0.9887 - val_loss: 1.5446 - val_acc: 0.7773\n",
      "Epoch 364/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1117 - acc: 0.9823 - val_loss: 1.7658 - val_acc: 0.7682\n",
      "Epoch 365/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1409 - acc: 0.9815 - val_loss: 1.8247 - val_acc: 0.7545\n",
      "Epoch 366/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.1107 - acc: 0.9815 - val_loss: 1.5773 - val_acc: 0.8045\n",
      "Epoch 367/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.1254 - acc: 0.9815 - val_loss: 1.5673 - val_acc: 0.7773\n",
      "Epoch 368/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.1384 - acc: 0.9718 - val_loss: 1.6509 - val_acc: 0.7545\n",
      "Epoch 369/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.1590 - acc: 0.9718 - val_loss: 1.6138 - val_acc: 0.7682\n",
      "Epoch 370/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0967 - acc: 0.9863 - val_loss: 1.5678 - val_acc: 0.7591\n",
      "Epoch 371/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.1087 - acc: 0.9839 - val_loss: 1.6134 - val_acc: 0.7682\n",
      "Epoch 372/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1085 - acc: 0.9879 - val_loss: 1.5920 - val_acc: 0.7818\n",
      "Epoch 373/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0801 - acc: 0.9928 - val_loss: 1.5323 - val_acc: 0.7773\n",
      "Epoch 374/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0852 - acc: 0.9952 - val_loss: 1.5294 - val_acc: 0.7818\n",
      "Epoch 375/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0918 - acc: 0.9928 - val_loss: 1.6911 - val_acc: 0.7773\n",
      "Epoch 376/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0828 - acc: 0.9960 - val_loss: 1.5699 - val_acc: 0.7727\n",
      "Epoch 377/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0734 - acc: 0.9976 - val_loss: 1.6062 - val_acc: 0.7682\n",
      "Epoch 378/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0700 - acc: 0.9984 - val_loss: 1.5815 - val_acc: 0.7591\n",
      "Epoch 379/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0702 - acc: 0.9976 - val_loss: 1.6649 - val_acc: 0.7500\n",
      "Epoch 380/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0692 - acc: 0.9984 - val_loss: 1.6391 - val_acc: 0.7500\n",
      "Epoch 381/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0684 - acc: 0.9976 - val_loss: 1.6222 - val_acc: 0.7636\n",
      "Epoch 382/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0681 - acc: 0.9984 - val_loss: 1.6355 - val_acc: 0.7500\n",
      "Epoch 383/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0688 - acc: 0.9976 - val_loss: 1.6666 - val_acc: 0.7455\n",
      "Epoch 384/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0694 - acc: 0.9976 - val_loss: 1.6437 - val_acc: 0.7545\n",
      "Epoch 385/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0703 - acc: 0.9976 - val_loss: 1.6809 - val_acc: 0.7409\n",
      "Epoch 386/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0692 - acc: 0.9984 - val_loss: 1.6551 - val_acc: 0.7773\n",
      "Epoch 387/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0726 - acc: 0.9960 - val_loss: 1.6199 - val_acc: 0.7682\n",
      "Epoch 388/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0749 - acc: 0.9960 - val_loss: 1.6446 - val_acc: 0.7500\n",
      "Epoch 389/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0967 - acc: 0.9919 - val_loss: 1.6914 - val_acc: 0.7636\n",
      "Epoch 390/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.1071 - acc: 0.9895 - val_loss: 1.7316 - val_acc: 0.7545\n",
      "Epoch 391/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0787 - acc: 0.9968 - val_loss: 1.6673 - val_acc: 0.7636\n",
      "Epoch 392/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0788 - acc: 0.9952 - val_loss: 1.5729 - val_acc: 0.7727\n",
      "Epoch 393/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0837 - acc: 0.9928 - val_loss: 1.6888 - val_acc: 0.7682\n",
      "Epoch 394/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0744 - acc: 0.9960 - val_loss: 1.6988 - val_acc: 0.7545\n",
      "Epoch 395/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0717 - acc: 0.9968 - val_loss: 1.6694 - val_acc: 0.7545\n",
      "Epoch 396/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0678 - acc: 0.9984 - val_loss: 1.6972 - val_acc: 0.7591\n",
      "Epoch 397/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0683 - acc: 0.9976 - val_loss: 1.6908 - val_acc: 0.7500\n",
      "Epoch 398/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0669 - acc: 0.9984 - val_loss: 1.7001 - val_acc: 0.7636\n",
      "Epoch 399/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0666 - acc: 0.9976 - val_loss: 1.7033 - val_acc: 0.7591\n",
      "Epoch 400/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0668 - acc: 0.9984 - val_loss: 1.7042 - val_acc: 0.7636\n",
      "Epoch 401/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0672 - acc: 0.9984 - val_loss: 1.7206 - val_acc: 0.7636\n",
      "Epoch 402/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0680 - acc: 0.9976 - val_loss: 1.7206 - val_acc: 0.7455\n",
      "Epoch 403/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0693 - acc: 0.9968 - val_loss: 1.7340 - val_acc: 0.7636\n",
      "Epoch 404/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0679 - acc: 0.9984 - val_loss: 1.7066 - val_acc: 0.7682\n",
      "Epoch 405/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0666 - acc: 0.9984 - val_loss: 1.7335 - val_acc: 0.7682\n",
      "Epoch 406/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0689 - acc: 0.9976 - val_loss: 1.7451 - val_acc: 0.7636\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0677 - acc: 0.9984 - val_loss: 1.7257 - val_acc: 0.7591\n",
      "Epoch 408/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0671 - acc: 0.9984 - val_loss: 1.7572 - val_acc: 0.7545\n",
      "Epoch 409/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.0683 - acc: 0.9968 - val_loss: 1.7386 - val_acc: 0.7636\n",
      "Epoch 410/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0691 - acc: 0.9960 - val_loss: 1.7468 - val_acc: 0.7636\n",
      "Epoch 411/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0677 - acc: 0.9976 - val_loss: 1.7310 - val_acc: 0.7636\n",
      "Epoch 412/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0662 - acc: 0.9976 - val_loss: 1.7516 - val_acc: 0.7682\n",
      "Epoch 413/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0663 - acc: 0.9984 - val_loss: 1.7547 - val_acc: 0.7591\n",
      "Epoch 414/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0665 - acc: 0.9976 - val_loss: 1.7571 - val_acc: 0.7591\n",
      "Epoch 415/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0650 - acc: 0.9984 - val_loss: 1.7549 - val_acc: 0.7727\n",
      "Epoch 416/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0682 - acc: 0.9984 - val_loss: 1.7348 - val_acc: 0.7636\n",
      "Epoch 417/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0656 - acc: 0.9976 - val_loss: 1.7470 - val_acc: 0.7682\n",
      "Epoch 418/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0678 - acc: 0.9984 - val_loss: 1.7452 - val_acc: 0.7682\n",
      "Epoch 419/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0684 - acc: 0.9960 - val_loss: 1.7676 - val_acc: 0.7636\n",
      "Epoch 420/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0671 - acc: 0.9976 - val_loss: 1.7558 - val_acc: 0.7636\n",
      "Epoch 421/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0679 - acc: 0.9968 - val_loss: 1.7655 - val_acc: 0.7636\n",
      "Epoch 422/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0662 - acc: 0.9984 - val_loss: 1.7579 - val_acc: 0.7591\n",
      "Epoch 423/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0655 - acc: 0.9976 - val_loss: 1.7737 - val_acc: 0.7591\n",
      "Epoch 424/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0669 - acc: 0.9968 - val_loss: 1.7816 - val_acc: 0.7545\n",
      "Epoch 425/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0649 - acc: 0.9984 - val_loss: 1.7729 - val_acc: 0.7636\n",
      "Epoch 426/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0653 - acc: 0.9976 - val_loss: 1.7901 - val_acc: 0.7636\n",
      "Epoch 427/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0667 - acc: 0.9968 - val_loss: 1.7719 - val_acc: 0.7591\n",
      "Epoch 428/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0650 - acc: 0.9984 - val_loss: 1.7758 - val_acc: 0.7727\n",
      "Epoch 429/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0674 - acc: 0.9976 - val_loss: 1.7698 - val_acc: 0.7727\n",
      "Epoch 430/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.0657 - acc: 0.9976 - val_loss: 1.7920 - val_acc: 0.7636\n",
      "Epoch 431/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0653 - acc: 0.9968 - val_loss: 1.7819 - val_acc: 0.7682\n",
      "Epoch 432/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0646 - acc: 0.9976 - val_loss: 1.7802 - val_acc: 0.7727\n",
      "Epoch 433/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0654 - acc: 0.9984 - val_loss: 1.7999 - val_acc: 0.7636\n",
      "Epoch 434/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0662 - acc: 0.9984 - val_loss: 1.7898 - val_acc: 0.7682\n",
      "Epoch 435/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0666 - acc: 0.9976 - val_loss: 1.7946 - val_acc: 0.7682\n",
      "Epoch 436/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0659 - acc: 0.9984 - val_loss: 1.8114 - val_acc: 0.7636\n",
      "Epoch 437/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0651 - acc: 0.9968 - val_loss: 1.7974 - val_acc: 0.7636\n",
      "Epoch 438/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0649 - acc: 0.9976 - val_loss: 1.7973 - val_acc: 0.7591\n",
      "Epoch 439/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0655 - acc: 0.9976 - val_loss: 1.7975 - val_acc: 0.7591\n",
      "Epoch 440/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0684 - acc: 0.9968 - val_loss: 1.7880 - val_acc: 0.7727\n",
      "Epoch 441/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0656 - acc: 0.9984 - val_loss: 1.7743 - val_acc: 0.7773\n",
      "Epoch 442/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0646 - acc: 0.9984 - val_loss: 1.8002 - val_acc: 0.7682\n",
      "Epoch 443/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0650 - acc: 0.9976 - val_loss: 1.8061 - val_acc: 0.7682\n",
      "Epoch 444/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0645 - acc: 0.9984 - val_loss: 1.8012 - val_acc: 0.7682\n",
      "Epoch 445/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0648 - acc: 0.9984 - val_loss: 1.8158 - val_acc: 0.7682\n",
      "Epoch 446/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0651 - acc: 0.9968 - val_loss: 1.8107 - val_acc: 0.7682\n",
      "Epoch 447/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0669 - acc: 0.9984 - val_loss: 1.7984 - val_acc: 0.7682\n",
      "Epoch 448/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0648 - acc: 0.9984 - val_loss: 1.7984 - val_acc: 0.7682\n",
      "Epoch 449/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0663 - acc: 0.9984 - val_loss: 1.8064 - val_acc: 0.7682\n",
      "Epoch 450/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0641 - acc: 0.9968 - val_loss: 1.7846 - val_acc: 0.7682\n",
      "Epoch 451/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0654 - acc: 0.9976 - val_loss: 1.8033 - val_acc: 0.7682\n",
      "Epoch 452/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0642 - acc: 0.9984 - val_loss: 1.8040 - val_acc: 0.7682\n",
      "Epoch 453/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0655 - acc: 0.9976 - val_loss: 1.8042 - val_acc: 0.7682\n",
      "Epoch 454/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0662 - acc: 0.9976 - val_loss: 1.8218 - val_acc: 0.7727\n",
      "Epoch 455/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.0653 - acc: 0.9984 - val_loss: 1.8275 - val_acc: 0.7682\n",
      "Epoch 456/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0652 - acc: 0.9976 - val_loss: 1.8192 - val_acc: 0.7682\n",
      "Epoch 457/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0645 - acc: 0.9968 - val_loss: 1.8136 - val_acc: 0.7682\n",
      "Epoch 458/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0640 - acc: 0.9976 - val_loss: 1.8299 - val_acc: 0.7636\n",
      "Epoch 459/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0654 - acc: 0.9984 - val_loss: 1.8378 - val_acc: 0.7591\n",
      "Epoch 460/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0633 - acc: 0.9992 - val_loss: 1.8224 - val_acc: 0.7727\n",
      "Epoch 461/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0654 - acc: 0.9976 - val_loss: 1.8130 - val_acc: 0.7727\n",
      "Epoch 462/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0641 - acc: 0.9976 - val_loss: 1.8300 - val_acc: 0.7636\n",
      "Epoch 463/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0651 - acc: 0.9976 - val_loss: 1.8491 - val_acc: 0.7636\n",
      "Epoch 464/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0652 - acc: 0.9976 - val_loss: 1.8141 - val_acc: 0.7682\n",
      "Epoch 465/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0663 - acc: 0.9976 - val_loss: 1.8320 - val_acc: 0.7682\n",
      "Epoch 466/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0674 - acc: 0.9976 - val_loss: 1.8706 - val_acc: 0.7636\n",
      "Epoch 467/500\n",
      "1242/1242 [==============================] - 0s 28us/step - loss: 0.0668 - acc: 0.9976 - val_loss: 1.8068 - val_acc: 0.7682\n",
      "Epoch 468/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0649 - acc: 0.9984 - val_loss: 1.8274 - val_acc: 0.7591\n",
      "Epoch 469/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0653 - acc: 0.9968 - val_loss: 1.8654 - val_acc: 0.7727\n",
      "Epoch 470/500\n",
      "1242/1242 [==============================] - 0s 27us/step - loss: 0.0657 - acc: 0.9984 - val_loss: 1.8364 - val_acc: 0.7591\n",
      "Epoch 471/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0656 - acc: 0.9976 - val_loss: 1.8251 - val_acc: 0.7682\n",
      "Epoch 472/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0635 - acc: 0.9984 - val_loss: 1.8366 - val_acc: 0.7591\n",
      "Epoch 473/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0641 - acc: 0.9984 - val_loss: 1.8402 - val_acc: 0.7636\n",
      "Epoch 474/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0636 - acc: 0.9976 - val_loss: 1.8349 - val_acc: 0.7682\n",
      "Epoch 475/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0651 - acc: 0.9984 - val_loss: 1.8575 - val_acc: 0.7591\n",
      "Epoch 476/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0639 - acc: 0.9984 - val_loss: 1.8171 - val_acc: 0.7636\n",
      "Epoch 477/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0636 - acc: 0.9984 - val_loss: 1.8362 - val_acc: 0.7636\n",
      "Epoch 478/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0638 - acc: 0.9984 - val_loss: 1.8626 - val_acc: 0.7636\n",
      "Epoch 479/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0640 - acc: 0.9976 - val_loss: 1.8272 - val_acc: 0.7636\n",
      "Epoch 480/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0632 - acc: 0.9984 - val_loss: 1.8390 - val_acc: 0.7636\n",
      "Epoch 481/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0633 - acc: 0.9984 - val_loss: 1.8447 - val_acc: 0.7591\n",
      "Epoch 482/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0646 - acc: 0.9976 - val_loss: 1.8773 - val_acc: 0.7682\n",
      "Epoch 483/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0650 - acc: 0.9960 - val_loss: 1.8491 - val_acc: 0.7682\n",
      "Epoch 484/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0642 - acc: 0.9984 - val_loss: 1.8338 - val_acc: 0.7682\n",
      "Epoch 485/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0637 - acc: 0.9976 - val_loss: 1.8521 - val_acc: 0.7682\n",
      "Epoch 486/500\n",
      "1242/1242 [==============================] - 0s 21us/step - loss: 0.0686 - acc: 0.9952 - val_loss: 1.8274 - val_acc: 0.7682\n",
      "Epoch 487/500\n",
      "1242/1242 [==============================] - 0s 24us/step - loss: 0.0655 - acc: 0.9968 - val_loss: 1.8392 - val_acc: 0.7545\n",
      "Epoch 488/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0703 - acc: 0.9952 - val_loss: 1.8657 - val_acc: 0.7727\n",
      "Epoch 489/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0766 - acc: 0.9936 - val_loss: 1.8636 - val_acc: 0.7773\n",
      "Epoch 490/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0717 - acc: 0.9952 - val_loss: 1.7857 - val_acc: 0.7864\n",
      "Epoch 491/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0944 - acc: 0.9871 - val_loss: 1.7638 - val_acc: 0.7955\n",
      "Epoch 492/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.1030 - acc: 0.9831 - val_loss: 1.6468 - val_acc: 0.7773\n",
      "Epoch 493/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0860 - acc: 0.9911 - val_loss: 1.6851 - val_acc: 0.7636\n",
      "Epoch 494/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0737 - acc: 0.9952 - val_loss: 1.8409 - val_acc: 0.7545\n",
      "Epoch 495/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.0796 - acc: 0.9952 - val_loss: 1.5722 - val_acc: 0.7818\n",
      "Epoch 496/500\n",
      "1242/1242 [==============================] - 0s 25us/step - loss: 0.0954 - acc: 0.9871 - val_loss: 1.6917 - val_acc: 0.7864\n",
      "Epoch 497/500\n",
      "1242/1242 [==============================] - 0s 26us/step - loss: 0.1406 - acc: 0.9791 - val_loss: 1.5831 - val_acc: 0.7818\n",
      "Epoch 498/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1242 - acc: 0.9742 - val_loss: 1.7753 - val_acc: 0.7636\n",
      "Epoch 499/500\n",
      "1242/1242 [==============================] - 0s 23us/step - loss: 0.1278 - acc: 0.9775 - val_loss: 1.5854 - val_acc: 0.7864\n",
      "Epoch 500/500\n",
      "1242/1242 [==============================] - 0s 22us/step - loss: 0.0940 - acc: 0.9871 - val_loss: 1.5926 - val_acc: 0.7636\n",
      "Test loss: 1.5926054477691651\n",
      "Test accuracy: 0.7636363658038052\n",
      "AUC 0.8726246784499211\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/guided_backprop_ckpt\n",
      "(220, 41)\n",
      "Precipitation_Warmest_Quarter\n",
      "['PET_Seasonality' 'Isothermality' 'Precipitation_Coldest_Quarter'\n",
      " 'Precipitation_Seasonality' 'Aridity_Index_Thornthwaite'\n",
      " 'PET_Driest_Quarter' 'Max_Temp_Coldest' 'Precipitation_Wettest_Month'\n",
      " 'Mean_Temp_Wettest_Quarter' 'Precipitation_Wettest_Quarter'\n",
      " 'Mean_Temp_Coldest_Quarter' 'Organic_Carbon' 'PhCaCL'\n",
      " 'Temperature_Seasonality' 'Aspect' 'Temp_Annual_Range'\n",
      " 'Mean_Temp_Driest_Quarter' 'Moisture_Index' 'Bulk_Density' 'Emberger_Q'\n",
      " 'Growing_Deg_Days5' 'Max_Temp_Warmest_Month' 'Slope'\n",
      " 'Annual_Mean_Temperature' 'PET_Warmest_Quarter' 'Min_Temp_Warmest'\n",
      " 'Annual_Precipitation' 'Month_Count_by_Temp' 'Min_Temp_Coldest_Month'\n",
      " 'Thermicity_Index' 'Mean_Temp_Warmest_Quarter' 'Annual_PET'\n",
      " 'Clay_Percentage' 'PET_Wettest_Quarter' 'Precipitation_Driest_Month'\n",
      " 'Continentality' 'Growing_Deg_Days0' 'PET_Coldest_Quarter'\n",
      " 'Precipitation_Driest_Quarter' 'Mean_Diurnal_Temp_Range'\n",
      " 'Precipitation_Warmest_Quarter']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    table = pd.read_csv(file_dir +\"/data/capriolus_trial/Capriolus_capriolus_env_dataframe.csv\")\n",
    "    table =table.loc[:1500]\n",
    "    # at 40 degrees latitude\n",
    "    bin_size_km = 5\n",
    "    one_degree_latitude_km = 111.03  # http://www.longitudestore.com/how-big-is-one-gps-degree.html\n",
    "    one_degree_longitude_km = 85.39\n",
    "    step_latitude = 1. / one_degree_latitude_km * bin_size_km\n",
    "    step_longitude = 1. / one_degree_longitude_km * bin_size_km\n",
    "    # print(\"step_latitude, step_longitude\", step_latitude, step_longitude)\n",
    "\n",
    "    # remove spaces from column names\n",
    "    for column in table.columns:\n",
    "        table[column.strip()] = table[column]\n",
    "        if column.strip() != column:\n",
    "            del table[column]\n",
    "    # print(table.columns)\n",
    "    # print(table.decimal_latitude.min(), table.decimal_latitude.max())\n",
    "\n",
    "    latitude_min = table.decimal_latitude.min()\n",
    "    longitude_min = table.decimal_longitude.min()\n",
    "    table.decimal_latitude = table.decimal_latitude.apply(lambda x: (x - latitude_min) // step_latitude)\n",
    "    table.decimal_longitude = table.decimal_longitude.apply(lambda x: (x - longitude_min) // step_longitude)\n",
    "    table.decimal_latitude = table.decimal_latitude.astype(int)\n",
    "    table.decimal_longitude = table.decimal_longitude.astype(int)\n",
    "\n",
    "    # make feature vector\n",
    "    band_columns = [column for column in table.columns[8:]]\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, row in table.iterrows():\n",
    "        x = row[band_columns].values\n",
    "        if (np.any(x <= -9999.0)):  # in sea?\n",
    "            continue\n",
    "        # print(row[\"present/pseudo_absent\"], np.where(x <= -9999.0)[0])\n",
    "        x = x.tolist()\n",
    "        x.append(row[\"present/pseudo_absent\"])\n",
    "        X.append(x)\n",
    "\n",
    "    df = pd.DataFrame(data=X, columns=band_columns + [\"presence\"])\n",
    "    df.to_csv(\"filtered.csv\", index=None)\n",
    "\n",
    "    print(len(df[df[\"presence\" ]==1]))\n",
    "    print(len(df[df[\"presence\" ]==0]))\n",
    "\n",
    "    # Scale feature values\n",
    "    for column in df.columns[:-1]:\n",
    "        # if \"band\" in column:\n",
    "        std_dev = np.std(df[column])\n",
    "        mean_ = np.mean(df[column])\n",
    "        df[column] = df[column].apply(lambda x: (x - mean_) / std_dev)\n",
    "    df.to_csv(\"normalized.csv\", index=None)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    band_columns = [column for column in df.columns[:-1]]\n",
    "    # print(band_columns)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        X.append(row[band_columns].values.tolist())\n",
    "        y.append([1 - row[\"presence\"], row[\"presence\"]])\n",
    "\n",
    "    X = np.vstack(X)\n",
    "    y = np.vstack(y)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "\n",
    "    batch_size = 100\n",
    "    num_classes = 2\n",
    "    epochs = 500\n",
    "    \n",
    "    num_inputs = X.shape[1]  # number of features\n",
    "\n",
    "    #reducelr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-8,\n",
    "     #                                     verbose=1)\n",
    "    \n",
    "    model = Sequential()\n",
    "    layer_1 = Dense(50, activation='relu',input_shape=(num_inputs,), kernel_regularizer=regularizers.l1(0.0001))\n",
    "\n",
    "    layer_2 = Dense(25, activation='relu', input_shape=(num_inputs,), kernel_regularizer=regularizers.l1(0.0001))\n",
    "    layer_3 = Dense(25, activation='relu', input_shape=(num_inputs,), kernel_regularizer=regularizers.l1(0.0001))\n",
    "    layer_4 = Dense(25, activation='relu', input_shape=(num_inputs,), kernel_regularizer=regularizers.l1(0.0001))\n",
    "    \n",
    "    \n",
    "    model.add(layer_1)\n",
    "   # model.add(Dropout(0.5))\n",
    "    model.add(layer_2)\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(layer_3)\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(layer_4)\n",
    "    #model.add(Dropout(0.5))\n",
    "  \n",
    "    \n",
    "    \n",
    "    # model.add(Lambda(lambda x: K.dropout(x, level=0.5)))\n",
    "    # model.add(Dense(512, activation='relu',\n",
    "    #             # kernel_regularizer=regularizers.l2(0.01),\n",
    "    #             # activity_regularizer=regularizers.l1(0.01)\n",
    "    #                 ))\n",
    "    # model.add(Dropout(0.5))\n",
    "    # model.add(Lambda(lambda x: K.dropout(x, level=0.5)))\n",
    "    out_layer = Dense(num_classes, activation=None)\n",
    "    model.add(out_layer)\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss=\"categorical_crossentropy\",\n",
    "                # optimizer =SGD(lr=0.001, momentum =0.9, nesterov=True),\n",
    "                # optimizer=Adagrad(lr=0.001),\n",
    "                # optimizer=RMSprop(lr=0.001),# rho=0.9, epsilon=1e-08, decay=0.0),\n",
    "                optimizer=Adam(lr=0.001),#, rho=0.9, epsilon=1e-08, decay=0.0),\n",
    "                metrics =['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train,\n",
    "    batch_size =batch_size,\n",
    "    epochs =epochs,\n",
    "    verbose =1,\n",
    "    validation_data =(X_test, y_test),\n",
    "    callbacks =[],\n",
    "    shuffle =True,\n",
    "    class_weight ={\n",
    "        0: 1,\n",
    "        1: 1,\n",
    "    }\n",
    "    )\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"AUC\", roc_auc_score(y_test[:, 1], predictions[:, 1]))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test[:, 1], predictions[:, 1])\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.show()\n",
    "    \n",
    "    guided_bprop = GuidedBackprop(model)\n",
    "    #mask = guided_bprop.get_mask(X_test[0])\n",
    "    masks = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        masks.append(guided_bprop.get_mask(X_test[i]))\n",
    "        #print(masks[-1].shape)\n",
    "    print(np.vstack(masks).shape)\n",
    "    mask = np.mean(np.vstack(masks), axis=0)\n",
    "    print(band_columns[mask.argmax()])\n",
    "    print(np.array(band_columns)[mask.argsort()])\n",
    "    \n",
    "    for i, xy in enumerate(zip(fpr, tpr)):\n",
    "        plt.gca().annotate(str(thresholds[i]), xy=xy, textcoords='data')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
