{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import plotting_extent\n",
    "from natsort import natsorted\n",
    "import gdal\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas\n",
    "import rasterio\n",
    "import pycrs\n",
    "\n",
    "file_dir=r'C:/Users/Mark.Rademaker/PycharmProjects/InternshipNaturalis/venv/github_trait_geo_diverse_dl/trait-geo-diverse-dl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#access file with list of taxa names\n",
    "taxa=pd.read_csv(file_dir+\"/data/SQL_filtered_gbif/taxa_list.txt\",header=None)\n",
    "taxa.columns=[\"taxon\"]\n",
    "\n",
    "species_occ_dict={}\n",
    "\n",
    "for i in taxa[\"taxon\"]:\n",
    "    taxon_data = pd.read_csv(file_dir+\"/data/SQL_filtered_gbif/%s_filtered_data.csv\"%i)\n",
    "    #add species dataframe to dict\n",
    "    species_occ_dict[\"%s\"%i] = taxon_data  \n",
    "    #check whether all species have been included and inspect dictionary\n",
    "if len(species_occ_dict.keys())==len(taxa[\"taxon\"]):\n",
    "    print(\"All species dataframes now in dictionary\")\n",
    "else:\n",
    "    print(\"Error: not all species dataframe included\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1\n",
    "- First read in occurrence data\n",
    "- Create a copy that we can use in the original state later\n",
    "- Create a buffer around each occurrence point, merge it into a single polygon\n",
    "- Clip the environmental raster based on this extend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in species_occ_dict:    \n",
    "    #load occurrence data and set initial projection\n",
    "    data=species_occ_dict[key]\n",
    "    print(data.columns)\n",
    "    spec = key\n",
    "\n",
    "\n",
    "    data['coordinates'] = list(zip(data[\"decimal_longitude\"], data[\"decimal_latitude\"]))\n",
    "    data['coordinates'] = data[\"coordinates\"].apply(Point)\n",
    "    data[\"present/pseudo_absent\"]=1\n",
    "    geo_data=geopandas.GeoDataFrame(data, geometry='coordinates',crs={'init' :'epsg:4326'})\n",
    "\n",
    "    #change projection to azimuthal equidistant to calculate 1000km buffer around point\n",
    "    geo_data = geo_data.to_crs({'init': 'esri:54032'}) \n",
    "    buffer=geo_data.buffer(1000*1000)\n",
    "    buffer=buffer.to_crs(epsg=4326)\n",
    "\n",
    "    #create single large polygon from individual buffers\n",
    "    union_buffer=buffer.unary_union\n",
    "\n",
    "    #first clip the raster based on this extend \n",
    "    raster=rasterio.open(file_dir+'/data/GIS/env_stacked/ENVIREM_BIOCLIM_stacked.tif')\n",
    "    #specify output tif:\n",
    "    out_tif = file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec\n",
    "\n",
    "    #clip the raster:\n",
    "    out_img, out_transform = mask(dataset=raster, shapes=[union_buffer],crop=True)\n",
    "   \n",
    "    # Copy the metadata\n",
    "    out_meta = raster.meta.copy()\n",
    "\n",
    "    # Parse EPSG code\n",
    "    epsg_code = int(raster.crs.data['init'][5:])\n",
    "    out_meta.update({\"driver\": \"GTiff\",\n",
    "                     \"height\": out_img.shape[1],\n",
    "                     \"width\": out_img.shape[2],\n",
    "                     \"transform\": out_transform,\n",
    "                     \"crs\": pycrs.parse.from_epsg_code(epsg_code).to_proj4()})\n",
    "\n",
    "    with rasterio.open(out_tif, \"w\", **out_meta) as dest:\n",
    "            dest.write(out_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect whether clip was correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the first band of the clipped raster for all species\n",
    "for key in species_occ_dict:\n",
    "    ##### Extract occurrence point to plot on the raster (see if correct area was clipped)\n",
    "    data=species_occ_dict[key]\n",
    "    spec = key\n",
    "    data['coordinates'] = list(zip(data[\"decimal_longitude\"], data[\"decimal_latitude\"]))\n",
    "    data['coordinates'] = data[\"coordinates\"].apply(Point)\n",
    "    geo_data=geopandas.GeoDataFrame(data, geometry='coordinates',crs={'init' :'epsg:4326'})\n",
    "    ####open the clipped raster\n",
    "    clipped = rasterio.open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    array = clipped.read(1)\n",
    "    array_data = clipped.read(1,masked=True)\n",
    "    array_meta = clipped.profile\n",
    "   \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(array_data,cmap=\"gist_earth\",interpolation=\"none\",vmin=0,\n",
    "    # Here you must set the spatial extent or else the data will not line up with your geopandas layer\n",
    "    extent=plotting_extent(clipped),)\n",
    "    spec_plots_points=geo_data[\"coordinates\"]\n",
    "    spec_plots_points.plot(ax=ax,\n",
    "                       marker='o',\n",
    "                       markersize=20,\n",
    "                       color='red')\n",
    "    ax.set_title(\"%s \\n Raster clip and occurrence points\"%spec,\n",
    "             fontsize=20)\n",
    "    plt.show()\n",
    "#Works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2\n",
    "- now that we have the clipped raster we can use it to try and make a random selection of pseudo absence points\n",
    "- we first open the raster\n",
    "- then we separate those cells that actually contain pixel values (excluding the sea)\n",
    "- we calculate the longitude and latitude of the centre point of these cells <br>\n",
    "  (the environmental variable values do not vary within each cell so it doesn't matter if each points is in the centre)\n",
    "- we make a random selection of 10.0000 positions\n",
    "- we add the longitude and latitude values of these to to the dataset and export it  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in species_occ_dict:    \n",
    "    #lon_lat presence points\n",
    "    presence_data = species_occ_dict[key]\n",
    "    presence_data[\"present/pseudo_absent\"]=1\n",
    "    spec = key\n",
    "    long=presence_data[\"decimal_longitude\"]\n",
    "    lati=presence_data[\"decimal_latitude\"]\n",
    "    long=pd.Series.tolist(long)\n",
    "    lati=pd.Series.tolist(lati)\n",
    "\n",
    "    #read raster\n",
    "    src=rasterio.open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    array=src.read_masks(1)\n",
    "\n",
    "    #set raster cell mask values of presence locations to 1\n",
    "    for i in range(0,len(presence_data)):\n",
    "        row,col=src.index(long[i],lati[i])\n",
    "        array[row,col]=1\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    ax.imshow(array,cmap=\"gray\")\n",
    "    ax.set_title(\"%s\"%spec,\n",
    "             fontsize=20)\n",
    "    plt.show()\n",
    "    (y_index, x_index) = np.nonzero(array > 1)\n",
    "\n",
    "    #sample random locations from raster excluding sea and presence cells\n",
    "    r = gdal.Open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    (upper_left_x, x_size, x_rotation, upper_left_y, y_rotation, y_size) = r.GetGeoTransform()\n",
    "    x_coords = x_index * x_size + upper_left_x + (x_size / 2) #add half the cell size\n",
    "    y_coords = y_index * y_size + upper_left_y + (y_size / 2) #to centre the point\n",
    "\n",
    "\n",
    "    lon_lat_array=np.stack((x_coords,y_coords)).T\n",
    "\n",
    "    random_sample_size=int(len(presence_data))\n",
    "    random_sample_lon_lats=lon_lat_array[np.random.choice(lon_lat_array.shape[0], random_sample_size, replace=False), :] #first did 10.000 now equal to n presences\n",
    "    print(len(random_sample_lon_lats), \"number of pseudo absences\")\n",
    "\n",
    "    #Add random points to dataset\n",
    "    lon=[]\n",
    "    lat=[]\n",
    "    psa=[0]*random_sample_size\n",
    "    taxon=[\"%s\"%spec]*random_sample_size\n",
    "    gbif=[\"no_id\"]*random_sample_size\n",
    "\n",
    "    for item in random_sample_lon_lats:\n",
    "        longitude=item[0]\n",
    "        latitude=item[1]\n",
    "        lon.append(longitude)\n",
    "        lat.append(latitude)\n",
    "\n",
    "    ###Dataset including 10.000 pseudo-absence points for capriolus capriolus\n",
    "    new_data=pd.DataFrame({\"gbif_id\": gbif,\"taxon_name\":taxon,\"decimal_longitude\": lon, \"decimal_latitude\":lat, \"present/pseudo_absent\": psa})\n",
    "    data=pd.concat([presence_data,new_data],ignore_index=True)\n",
    "    data=data[['taxon_name','gbif_id','decimal_longitude','decimal_latitude','present/pseudo_absent']]\n",
    "    print(len(data),\"lenght data with pseudo absences\")\n",
    "    data.to_csv(file_dir + \"/data/spec_ppa/%s_ppa_dataframe.csv\"%spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(file_dir+'/data/spec_ppa/Capreolus_capreolus_ppa_dataframe.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ###Dataset including all locations with data-values (to later predict presence-pseudoabsence on)\n",
    "    src=rasterio.open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    array=src.read_masks(1)\n",
    "\n",
    "    r = gdal.Open(file_dir+'/data/GIS/spec_stacked_raster_clip/%s_raster_clip.tif'%spec)\n",
    "    (y_index, x_index) = np.nonzero(array > 0)\n",
    "    (upper_left_x, x_size, x_rotation, upper_left_y, y_rotation, y_size) = r.GetGeoTransform()\n",
    "    x_coords = x_index * x_size + upper_left_x + (x_size / 2) #add half the cell size\n",
    "    y_coords = y_index * y_size + upper_left_y + (y_size / 2) #to centre the point\n",
    "\n",
    "    lon_lat_array=np.stack((x_coords,y_coords)).T\n",
    "\n",
    "    lon=[]\n",
    "    lat=[]\n",
    "\n",
    "    for item in lon_lat_array:\n",
    "        longitude=item[0]\n",
    "        latitude=item[1]\n",
    "        lon.append(longitude)\n",
    "        lat.append(latitude)\n",
    "\n",
    "    taxon=[\"%s\"%spec]*len(lon)\n",
    "\n",
    "    data_to_pred=pd.DataFrame({\"taxon_name\":taxon, \"decimal_longitude\":lon,\"decimal_latitude\":lat})\n",
    "    print(len(data_to_pred), \"number of points to predict\")\n",
    "    data_to_pred.to_csv(file_dir + \"/data/capriolus_trial/%s_location_to_predict.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
